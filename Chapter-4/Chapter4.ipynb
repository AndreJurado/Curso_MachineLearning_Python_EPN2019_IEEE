{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Redes Neuronales\n",
    "\n",
    "<center>\n",
    "    \n",
    "<img src='images/Neuron.svg' width=60%\\>\n",
    "</center>\n",
    "\n",
    "[Fuente Wikipedia](https://commons.wikimedia.org/w/index.php?title=File:Neuron.svg&oldid=343028396)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Una red neuronal es una estructura compuesta por **nodos** o **unidades** que se encuentran interconectados. La potencia de la interconexión entre los nodos se evalúa por medio un valor de **peso**. Si la suma ponderada de todas las conexiones al **nodo** o **neurona** es mayor que un **valor umbral**, decimos que la neurona se **activa**. La función matemática aplicada a la suma ponderada se denomina **función de activación**. \n",
    "\n",
    "Se denomina **Modelo de Perceptrón** a una red neuronal con una sola salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"174pt\" height=\"261pt\"\n",
       " viewBox=\"0.00 0.00 174.00 261.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 257)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-257 170,-257 170,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_0</title>\n",
       "<polygon fill=\"none\" stroke=\"#ffffff\" points=\"8,-8 8,-245 60,-245 60,-8 8,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-229.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">inputs</text>\n",
       "</g>\n",
       "<g id=\"clust2\" class=\"cluster\">\n",
       "<title>cluster_2</title>\n",
       "<polygon fill=\"none\" stroke=\"#ffffff\" points=\"106,-89 106,-164 158,-164 158,-89 106,-89\"/>\n",
       "<text text-anchor=\"middle\" x=\"132\" y=\"-148.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">output</text>\n",
       "</g>\n",
       "<!-- x[0] -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>x[0]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"34\" cy=\"-196\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-192.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x[0]</text>\n",
       "</g>\n",
       "<!-- y -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>y</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"132\" cy=\"-115\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"132\" y=\"-111.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">y</text>\n",
       "</g>\n",
       "<!-- x[0]&#45;&gt;y -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>x[0]&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M48.041,-184.3947C64.2693,-170.9815 91.1723,-148.7454 110.144,-133.0647\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"112.5069,-135.6525 117.985,-126.5838 108.0473,-130.2569 112.5069,-135.6525\"/>\n",
       "<text text-anchor=\"middle\" x=\"83\" y=\"-171.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">w[0]</text>\n",
       "</g>\n",
       "<!-- x[1] -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>x[1]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"34\" cy=\"-142\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-138.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x[1]</text>\n",
       "</g>\n",
       "<!-- x[1]&#45;&gt;y -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>x[1]&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.5204,-137.1729C66.2924,-133.1031 87.6838,-127.2096 104.6999,-122.5214\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"105.9201,-125.8158 114.6312,-119.7853 104.0608,-119.0672 105.9201,-125.8158\"/>\n",
       "<text text-anchor=\"middle\" x=\"83\" y=\"-134.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">w[1]</text>\n",
       "</g>\n",
       "<!-- x[2] -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>x[2]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"34\" cy=\"-88\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-84.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x[2]</text>\n",
       "</g>\n",
       "<!-- x[2]&#45;&gt;y -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>x[2]&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.5204,-92.8271C66.2924,-96.8969 87.6838,-102.7904 104.6999,-107.4786\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"104.0608,-110.9328 114.6312,-110.2147 105.9201,-104.1842 104.0608,-110.9328\"/>\n",
       "<text text-anchor=\"middle\" x=\"83\" y=\"-107.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">w[2]</text>\n",
       "</g>\n",
       "<!-- x[3] -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>x[3]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"34\" cy=\"-34\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-30.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x[3]</text>\n",
       "</g>\n",
       "<!-- x[3]&#45;&gt;y -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>x[3]&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M48.041,-45.6053C64.2693,-59.0185 91.1723,-81.2546 110.144,-96.9353\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"108.0473,-99.7431 117.985,-103.4162 112.5069,-94.3475 108.0473,-99.7431\"/>\n",
       "<text text-anchor=\"middle\" x=\"83\" y=\"-82.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">w[3]</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7effc4ea22e8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mglearn\n",
    "mglearn.plots.plot_logistic_regression_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sea $\\mathbf{X}$ el espacio de entrada que contiene $N$ muestras de datos. Cada muestra está descrita por $d$ características o **features**. Sea $\\mathcal{Y} = \\{-1, +1\\}$ el espacio de salida binario. El perceptrón queda definido por:\n",
    "\n",
    "\n",
    "    \n",
    "$h(\\mathbf{x}) = sign \\left( \\sum_{i=1}^{d} \\left( w_ix_i \\right) + b \\right)$\n",
    "\n",
    "Donde **sign** es la función signo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Sea $\\mathbf{w} = \\{w_{0},w_{1}, w_{2}, \\dots, w_{d} \\}^T$ el vector de pesos; en donde $w_{0}=b$ y sea $\\mathbf{x} = \\{x_{0},x_{1}, x_{2}, \\dots, x_{d} \\}^T $ con $w_{0}=1$, entonces la expresión para el Perceptron se puede reescribir:\n",
    "\n",
    "$h(\\mathbf{x}) = sign \\left(  \\mathbf{w}^T \\mathbf{x} \\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Algoritmo de aprendizaje del perceptrón\n",
    "Para realizar el entrenamiento es preciso que las muestras de datos y etiquetas (o valores) sean randomizados. Luega en cada iteración se corregirá los valores del vector $\\mathbf{w}$, mediante la siguiente expresión:\n",
    "\n",
    "$\\mathbf{w}(t+1)=\\mathbf{w}(t)+\\alpha y(t)\\mathbf{x}(t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## El Perceptron  y la compuerta AND\n",
    "La compuerta **and** consta de 4 ejemplos. Cada uno con 2 características $d=2$. \n",
    "\n",
    "\n",
    "| muestra | x1 | x2 | y  |\n",
    "|---------|----|----|----|\n",
    "| 1       | -1 | -1 | -1 |\n",
    "| 2       | -1 |  1 | -1 |\n",
    "| 3       |  1 | -1 | -1 |\n",
    "| 4       |  1 | 1  |  1 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X es:\n",
      "[[-1 -1]\n",
      " [-1  1]\n",
      " [ 1 -1]\n",
      " [ 1  1]]\n",
      "Y es:\n",
      "[-1 -1 -1  1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array([[-1, -1], [-1, 1], [1, -1], [1, 1]])\n",
    "Y = np.array([-1, -1, -1, 1])\n",
    "print('X es:\\n{}'.format(X))\n",
    "print('Y es:\\n{}'.format(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1.41, NNZs: 2, Bias: -1.000000, T: 4, Avg. loss: 0.750000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.41, NNZs: 2, Bias: -1.000000, T: 8, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.41, NNZs: 2, Bias: -1.000000, T: 12, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.41, NNZs: 2, Bias: -1.000000, T: 16, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.41, NNZs: 2, Bias: -1.000000, T: 20, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Rendimiento del entrenamiento: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leninml/anaconda3/envs/MachineLearning/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "percept_and = Perceptron(verbose=1, shuffle=True)\n",
    "percept_and.fit(X, Y)\n",
    "print('Rendimiento del entrenamiento: {}'.format(percept_and.score(X,Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1,  1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = percept_and.predict(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ejercicio:\n",
    "1. Verifique que la Compuerta **XOR** No tiene solución con un Perceptron\n",
    "2. Verifique que la Computerta **OR** Tiene solución con un Perceptrón\n",
    "3. Escriba un programa en Python que ejecute el algoritmo de aprendizaje del Perceptrón"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Redes Neuronales Multicapa con Alimentación hacia adelante (Feed Forward)\n",
    "Al añadir capas ocultas a una estructra de redes neuronales se amplía el espacio de hipótesis. Una red sencilla con una capa oculta con 3 perceptrones es la indicada en la siguiente figura. Observe la estructura de izquiera a derecha formada por:\n",
    "\n",
    "* Capa de entrada\n",
    "* Capa oculta\n",
    "* Capa de Salida\n",
    "\n",
    "Note que la capa de salida puede tener más nodos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"252pt\" height=\"261pt\"\n",
       " viewBox=\"0.00 0.00 252.00 261.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 257)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-257 248,-257 248,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_0</title>\n",
       "<polygon fill=\"none\" stroke=\"#ffffff\" points=\"8,-8 8,-245 60,-245 60,-8 8,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-229.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">inputs</text>\n",
       "</g>\n",
       "<g id=\"clust2\" class=\"cluster\">\n",
       "<title>cluster_1</title>\n",
       "<polygon fill=\"none\" stroke=\"#ffffff\" points=\"80,-35 80,-218 164,-218 164,-35 80,-35\"/>\n",
       "<text text-anchor=\"middle\" x=\"122\" y=\"-202.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">hidden layer</text>\n",
       "</g>\n",
       "<g id=\"clust3\" class=\"cluster\">\n",
       "<title>cluster_2</title>\n",
       "<polygon fill=\"none\" stroke=\"#ffffff\" points=\"184,-89 184,-164 236,-164 236,-89 184,-89\"/>\n",
       "<text text-anchor=\"middle\" x=\"210\" y=\"-148.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">output</text>\n",
       "</g>\n",
       "<!-- x[0] -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>x[0]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"34\" cy=\"-196\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-192.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x[0]</text>\n",
       "</g>\n",
       "<!-- h0 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>h0</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"122\" cy=\"-61\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"122\" y=\"-57.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">h[0]</text>\n",
       "</g>\n",
       "<!-- x[0]&#45;&gt;h0 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>x[0]&#45;&gt;h0</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M43.9237,-180.7762C59.1082,-157.4817 88.244,-112.7848 106.311,-85.0684\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"109.4488,-86.6639 111.9776,-76.3753 103.5847,-82.8414 109.4488,-86.6639\"/>\n",
       "</g>\n",
       "<!-- h1 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>h1</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"122\" cy=\"-169\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"122\" y=\"-165.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">h[1]</text>\n",
       "</g>\n",
       "<!-- x[0]&#45;&gt;h1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>x[0]&#45;&gt;h1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.386,-190.6657C63.8004,-186.8567 80.7424,-181.6586 94.9198,-177.3087\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"96.1167,-180.6026 104.6501,-174.3232 94.0634,-173.9105 96.1167,-180.6026\"/>\n",
       "</g>\n",
       "<!-- h2 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>h2</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"122\" cy=\"-115\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"122\" y=\"-111.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">h[2]</text>\n",
       "</g>\n",
       "<!-- x[0]&#45;&gt;h2 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>x[0]&#45;&gt;h2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M47.3653,-183.6978C61.5794,-170.6144 84.2611,-149.7369 100.8935,-134.4276\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"103.5216,-136.7655 108.5089,-127.4179 98.7809,-131.6152 103.5216,-136.7655\"/>\n",
       "</g>\n",
       "<!-- x[1] -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>x[1]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"34\" cy=\"-142\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-138.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x[1]</text>\n",
       "</g>\n",
       "<!-- x[1]&#45;&gt;h0 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>x[1]&#45;&gt;h0</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M47.3653,-129.6978C61.5794,-116.6144 84.2611,-95.7369 100.8935,-80.4276\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"103.5216,-82.7655 108.5089,-73.4179 98.7809,-77.6152 103.5216,-82.7655\"/>\n",
       "</g>\n",
       "<!-- x[1]&#45;&gt;h1 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>x[1]&#45;&gt;h1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.386,-147.3343C63.8004,-151.1433 80.7424,-156.3414 94.9198,-160.6913\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"94.0634,-164.0895 104.6501,-163.6768 96.1167,-157.3974 94.0634,-164.0895\"/>\n",
       "</g>\n",
       "<!-- x[1]&#45;&gt;h2 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>x[1]&#45;&gt;h2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.386,-136.6657C63.8004,-132.8567 80.7424,-127.6586 94.9198,-123.3087\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"96.1167,-126.6026 104.6501,-120.3232 94.0634,-119.9105 96.1167,-126.6026\"/>\n",
       "</g>\n",
       "<!-- x[2] -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>x[2]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"34\" cy=\"-88\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-84.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x[2]</text>\n",
       "</g>\n",
       "<!-- x[2]&#45;&gt;h0 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>x[2]&#45;&gt;h0</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.386,-82.6657C63.8004,-78.8567 80.7424,-73.6586 94.9198,-69.3087\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"96.1167,-72.6026 104.6501,-66.3232 94.0634,-65.9105 96.1167,-72.6026\"/>\n",
       "</g>\n",
       "<!-- x[2]&#45;&gt;h1 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>x[2]&#45;&gt;h1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M47.3653,-100.3022C61.5794,-113.3856 84.2611,-134.2631 100.8935,-149.5724\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"98.7809,-152.3848 108.5089,-156.5821 103.5216,-147.2345 98.7809,-152.3848\"/>\n",
       "</g>\n",
       "<!-- x[2]&#45;&gt;h2 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>x[2]&#45;&gt;h2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.386,-93.3343C63.8004,-97.1433 80.7424,-102.3414 94.9198,-106.6913\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"94.0634,-110.0895 104.6501,-109.6768 96.1167,-103.3974 94.0634,-110.0895\"/>\n",
       "</g>\n",
       "<!-- x[3] -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>x[3]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"34\" cy=\"-34\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-30.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x[3]</text>\n",
       "</g>\n",
       "<!-- x[3]&#45;&gt;h0 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>x[3]&#45;&gt;h0</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.386,-39.3343C63.8004,-43.1433 80.7424,-48.3414 94.9198,-52.6913\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"94.0634,-56.0895 104.6501,-55.6768 96.1167,-49.3974 94.0634,-56.0895\"/>\n",
       "</g>\n",
       "<!-- x[3]&#45;&gt;h1 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>x[3]&#45;&gt;h1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M43.9237,-49.2238C59.1082,-72.5183 88.244,-117.2152 106.311,-144.9316\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"103.5847,-147.1586 111.9776,-153.6247 109.4488,-143.3361 103.5847,-147.1586\"/>\n",
       "</g>\n",
       "<!-- x[3]&#45;&gt;h2 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>x[3]&#45;&gt;h2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M47.3653,-46.3022C61.5794,-59.3856 84.2611,-80.2631 100.8935,-95.5724\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"98.7809,-98.3848 108.5089,-102.5821 103.5216,-93.2345 98.7809,-98.3848\"/>\n",
       "</g>\n",
       "<!-- y -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>y</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"210\" cy=\"-115\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"210\" y=\"-111.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">y</text>\n",
       "</g>\n",
       "<!-- h0&#45;&gt;y -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>h0&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M137.7326,-70.6541C150.9973,-78.7938 170.2058,-90.5808 185.4857,-99.9571\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"184.0498,-103.1824 194.4036,-105.4295 187.7109,-97.2161 184.0498,-103.1824\"/>\n",
       "</g>\n",
       "<!-- h1&#45;&gt;y -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>h1&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M137.7326,-159.3459C150.9973,-151.2062 170.2058,-139.4192 185.4857,-130.0429\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"187.7109,-132.7839 194.4036,-124.5705 184.0498,-126.8176 187.7109,-132.7839\"/>\n",
       "</g>\n",
       "<!-- h2&#45;&gt;y -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>h2&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M140.2337,-115C152.1508,-115 167.9616,-115 181.5183,-115\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"181.7897,-118.5001 191.7897,-115 181.7897,-111.5001 181.7897,-118.5001\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7eff6e2cbb38>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mglearn.plots.plot_single_hidden_layer_graph()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "La complejidad del problema puede requerir incrementar el número de capas ocultas. Para entrenar este tipo de redes se necesita el algoritmo de **back propagation** o retropropagación del error, ya que al tener varias neuronas en una capa oculta se dispone de un vector de hipótesis cuyos valores correctos no se conocen previamente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"378pt\" height=\"261pt\"\n",
       " viewBox=\"0.00 0.00 378.00 261.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 257)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-257 374,-257 374,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_0</title>\n",
       "<polygon fill=\"none\" stroke=\"#ffffff\" points=\"8,-8 8,-245 60,-245 60,-8 8,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-229.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">inputs</text>\n",
       "</g>\n",
       "<g id=\"clust2\" class=\"cluster\">\n",
       "<title>cluster_1</title>\n",
       "<polygon fill=\"none\" stroke=\"#ffffff\" points=\"80,-35 80,-218 175,-218 175,-35 80,-35\"/>\n",
       "<text text-anchor=\"middle\" x=\"127.5\" y=\"-202.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">hidden layer 1</text>\n",
       "</g>\n",
       "<g id=\"clust3\" class=\"cluster\">\n",
       "<title>cluster_2</title>\n",
       "<polygon fill=\"none\" stroke=\"#ffffff\" points=\"195,-35 195,-218 290,-218 290,-35 195,-35\"/>\n",
       "<text text-anchor=\"middle\" x=\"242.5\" y=\"-202.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">hidden layer 2</text>\n",
       "</g>\n",
       "<g id=\"clust4\" class=\"cluster\">\n",
       "<title>cluster_3</title>\n",
       "<polygon fill=\"none\" stroke=\"#ffffff\" points=\"310,-89 310,-164 362,-164 362,-89 310,-89\"/>\n",
       "<text text-anchor=\"middle\" x=\"336\" y=\"-148.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">output</text>\n",
       "</g>\n",
       "<!-- x[0] -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>x[0]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"34\" cy=\"-196\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-192.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x[0]</text>\n",
       "</g>\n",
       "<!-- h1[0] -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>h1[0]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"127\" cy=\"-61\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"127\" y=\"-57.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">h1[0]</text>\n",
       "</g>\n",
       "<!-- x[0]&#45;&gt;h1[0] -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>x[0]&#45;&gt;h1[0]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M44.308,-181.0368C60.4387,-157.6212 91.7762,-112.1314 110.9005,-84.3702\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"113.8551,-86.2509 116.6459,-76.0302 108.0905,-82.2797 113.8551,-86.2509\"/>\n",
       "</g>\n",
       "<!-- h1[1] -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>h1[1]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"127\" cy=\"-169\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"127\" y=\"-165.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">h1[1]</text>\n",
       "</g>\n",
       "<!-- x[0]&#45;&gt;h1[1] -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>x[0]&#45;&gt;h1[1]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.4926,-190.9215C65.1319,-186.9617 84.3149,-181.3924 99.9321,-176.8584\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"100.9582,-180.2051 109.5858,-174.0557 99.0065,-173.4827 100.9582,-180.2051\"/>\n",
       "</g>\n",
       "<!-- h1[2] -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>h1[2]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"127\" cy=\"-115\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"127\" y=\"-111.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">h1[2]</text>\n",
       "</g>\n",
       "<!-- x[0]&#45;&gt;h1[2] -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>x[0]&#45;&gt;h1[2]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M47.7225,-184.0482C62.9704,-170.7677 87.7855,-149.1546 105.5924,-133.6453\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"107.9791,-136.208 113.2212,-127.0009 103.3816,-130.9294 107.9791,-136.208\"/>\n",
       "</g>\n",
       "<!-- x[1] -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>x[1]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"34\" cy=\"-142\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-138.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x[1]</text>\n",
       "</g>\n",
       "<!-- x[1]&#45;&gt;h1[0] -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>x[1]&#45;&gt;h1[0]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M47.7225,-130.0482C62.9704,-116.7677 87.7855,-95.1546 105.5924,-79.6453\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"107.9791,-82.208 113.2212,-73.0009 103.3816,-76.9294 107.9791,-82.208\"/>\n",
       "</g>\n",
       "<!-- x[1]&#45;&gt;h1[1] -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>x[1]&#45;&gt;h1[1]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.4926,-147.0785C65.1319,-151.0383 84.3149,-156.6076 99.9321,-161.1416\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"99.0065,-164.5173 109.5858,-163.9443 100.9582,-157.7949 99.0065,-164.5173\"/>\n",
       "</g>\n",
       "<!-- x[1]&#45;&gt;h1[2] -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>x[1]&#45;&gt;h1[2]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.4926,-136.9215C65.1319,-132.9617 84.3149,-127.3924 99.9321,-122.8584\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"100.9582,-126.2051 109.5858,-120.0557 99.0065,-119.4827 100.9582,-126.2051\"/>\n",
       "</g>\n",
       "<!-- x[2] -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>x[2]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"34\" cy=\"-88\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-84.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x[2]</text>\n",
       "</g>\n",
       "<!-- x[2]&#45;&gt;h1[0] -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>x[2]&#45;&gt;h1[0]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.4926,-82.9215C65.1319,-78.9617 84.3149,-73.3924 99.9321,-68.8584\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"100.9582,-72.2051 109.5858,-66.0557 99.0065,-65.4827 100.9582,-72.2051\"/>\n",
       "</g>\n",
       "<!-- x[2]&#45;&gt;h1[1] -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>x[2]&#45;&gt;h1[1]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M47.7225,-99.9518C62.9704,-113.2323 87.7855,-134.8454 105.5924,-150.3547\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"103.3816,-153.0706 113.2212,-156.9991 107.9791,-147.792 103.3816,-153.0706\"/>\n",
       "</g>\n",
       "<!-- x[2]&#45;&gt;h1[2] -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>x[2]&#45;&gt;h1[2]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.4926,-93.0785C65.1319,-97.0383 84.3149,-102.6076 99.9321,-107.1416\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"99.0065,-110.5173 109.5858,-109.9443 100.9582,-103.7949 99.0065,-110.5173\"/>\n",
       "</g>\n",
       "<!-- x[3] -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>x[3]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"34\" cy=\"-34\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"34\" y=\"-30.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x[3]</text>\n",
       "</g>\n",
       "<!-- x[3]&#45;&gt;h1[0] -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>x[3]&#45;&gt;h1[0]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.4926,-39.0785C65.1319,-43.0383 84.3149,-48.6076 99.9321,-53.1416\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"99.0065,-56.5173 109.5858,-55.9443 100.9582,-49.7949 99.0065,-56.5173\"/>\n",
       "</g>\n",
       "<!-- x[3]&#45;&gt;h1[1] -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>x[3]&#45;&gt;h1[1]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M44.308,-48.9632C60.4387,-72.3788 91.7762,-117.8686 110.9005,-145.6298\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"108.0905,-147.7203 116.6459,-153.9698 113.8551,-143.7491 108.0905,-147.7203\"/>\n",
       "</g>\n",
       "<!-- x[3]&#45;&gt;h1[2] -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>x[3]&#45;&gt;h1[2]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M47.7225,-45.9518C62.9704,-59.2323 87.7855,-80.8454 105.5924,-96.3547\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"103.3816,-99.0706 113.2212,-102.9991 107.9791,-93.792 103.3816,-99.0706\"/>\n",
       "</g>\n",
       "<!-- h2[0] -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>h2[0]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"242\" cy=\"-61\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"242\" y=\"-57.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">h2[0]</text>\n",
       "</g>\n",
       "<!-- h1[0]&#45;&gt;h2[0] -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>h1[0]&#45;&gt;h2[0]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M145.2221,-61C163.6433,-61 192.3671,-61 213.7431,-61\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"213.8632,-64.5001 223.8632,-61 213.8631,-57.5001 213.8632,-64.5001\"/>\n",
       "</g>\n",
       "<!-- h2[1] -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>h2[1]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"242\" cy=\"-169\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"242\" y=\"-165.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">h2[1]</text>\n",
       "</g>\n",
       "<!-- h1[0]&#45;&gt;h2[1] -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>h1[0]&#45;&gt;h2[1]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M140.192,-73.389C160.0161,-92.0064 197.669,-127.3674 221.211,-149.4764\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"218.9222,-152.1284 228.6077,-156.4228 223.7142,-147.0258 218.9222,-152.1284\"/>\n",
       "</g>\n",
       "<!-- h2[2] -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>h2[2]</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"242\" cy=\"-115\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"242\" y=\"-111.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">h2[2]</text>\n",
       "</g>\n",
       "<!-- h1[0]&#45;&gt;h2[2] -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>h1[0]&#45;&gt;h2[2]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M143.4767,-68.7369C162.5201,-77.679 194.0899,-92.5031 216.3526,-102.9569\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"215.0145,-106.1951 225.5539,-107.2775 217.9898,-99.8589 215.0145,-106.1951\"/>\n",
       "</g>\n",
       "<!-- h1[1]&#45;&gt;h2[0] -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>h1[1]&#45;&gt;h2[0]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M140.192,-156.611C160.0161,-137.9936 197.669,-102.6326 221.211,-80.5236\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"223.7142,-82.9742 228.6077,-73.5772 218.9222,-77.8716 223.7142,-82.9742\"/>\n",
       "</g>\n",
       "<!-- h1[1]&#45;&gt;h2[1] -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>h1[1]&#45;&gt;h2[1]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M145.2221,-169C163.6433,-169 192.3671,-169 213.7431,-169\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"213.8632,-172.5001 223.8632,-169 213.8631,-165.5001 213.8632,-172.5001\"/>\n",
       "</g>\n",
       "<!-- h1[1]&#45;&gt;h2[2] -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>h1[1]&#45;&gt;h2[2]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M143.4767,-161.2631C162.5201,-152.321 194.0899,-137.4969 216.3526,-127.0431\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"217.9898,-130.1411 225.5539,-122.7225 215.0145,-123.8049 217.9898,-130.1411\"/>\n",
       "</g>\n",
       "<!-- h1[2]&#45;&gt;h2[0] -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>h1[2]&#45;&gt;h2[0]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M143.4767,-107.2631C162.5201,-98.321 194.0899,-83.4969 216.3526,-73.0431\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"217.9898,-76.1411 225.5539,-68.7225 215.0145,-69.8049 217.9898,-76.1411\"/>\n",
       "</g>\n",
       "<!-- h1[2]&#45;&gt;h2[1] -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>h1[2]&#45;&gt;h2[1]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M143.4767,-122.7369C162.5201,-131.679 194.0899,-146.5031 216.3526,-156.9569\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"215.0145,-160.1951 225.5539,-161.2775 217.9898,-153.8589 215.0145,-160.1951\"/>\n",
       "</g>\n",
       "<!-- h1[2]&#45;&gt;h2[2] -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>h1[2]&#45;&gt;h2[2]</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M145.2221,-115C163.6433,-115 192.3671,-115 213.7431,-115\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"213.8632,-118.5001 223.8632,-115 213.8631,-111.5001 213.8632,-118.5001\"/>\n",
       "</g>\n",
       "<!-- y -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>y</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"336\" cy=\"-115\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"336\" y=\"-111.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">y</text>\n",
       "</g>\n",
       "<!-- h2[0]&#45;&gt;y -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>h2[0]&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M257.9458,-70.1604C272.6188,-78.5895 294.6007,-91.2174 311.5017,-100.9265\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"309.8752,-104.0285 320.2897,-105.9749 313.3621,-97.9588 309.8752,-104.0285\"/>\n",
       "</g>\n",
       "<!-- h2[1]&#45;&gt;y -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>h2[1]&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M257.9458,-159.8396C272.6188,-151.4105 294.6007,-138.7826 311.5017,-129.0735\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"313.3621,-132.0412 320.2897,-124.0251 309.8752,-125.9715 313.3621,-132.0412\"/>\n",
       "</g>\n",
       "<!-- h2[2]&#45;&gt;y -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>h2[2]&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M260.1241,-115C273.6484,-115 292.3808,-115 307.8486,-115\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"307.9315,-118.5001 317.9315,-115 307.9315,-111.5001 307.9315,-118.5001\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7eff6e28f2e8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mglearn.plots.plot_two_hidden_layer_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ejercicio:\n",
    "Utilice una red neuronal multicapa para clasificar los datos del dataset moons, con:\n",
    "* Algoritmo de descenso de gradiente estocástico,\n",
    "* 50 neuronas en la capa oculta,\n",
    "* Función de activación relu, luego con sigmoid\n",
    "* Pruebe con algoritmo lbfgs y sgd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 1 1 1 0 0 0 1 0 1 1 0 1 1 0 1 0 1 0 0 0 1 1 0 1 0 1 0 0 0 0 1 0 1\n",
      " 1 0 0 0 0 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 0 0 0 0 0 1 1 0\n",
      " 1 1 0 1 1 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0]\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_moons\n",
    "X, y = make_moons(n_samples=100, noise=0.25, random_state=3)\n",
    "# print(X[0:5,:])\n",
    "print(y)\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Realicemos un plot de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "plt.figure()\n",
    "plt.scatter(X[:,0],X[:,1], c=y, cmap=cm_bright)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42) #, stratify=y\n",
    "red = MLPClassifier(hidden_layer_sizes=(50,), \n",
    "                    solver='lbfgs', \n",
    "#                     learning_rate_init=0.0001, \n",
    "#                     activation='relu', \n",
    "                    random_state=0, \n",
    "                    verbose=True, \n",
    "                    max_iter=1000)\n",
    "history = red.fit(X_train, y_train)\n",
    "\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.31702684, -0.2525239 ],\n",
       "       [ 1.15536561, -0.50593577],\n",
       "       [ 1.31311917, -0.69665985],\n",
       "       [ 0.8729088 ,  0.08643291],\n",
       "       [ 1.72532644,  0.53367598],\n",
       "       [-0.4993884 ,  0.13192906],\n",
       "       [ 0.35940317,  0.84867003],\n",
       "       [-0.16955317,  0.60660877],\n",
       "       [ 1.50917461, -0.06701048],\n",
       "       [ 0.36877983, -0.34894509],\n",
       "       [-0.7280717 ,  0.3259131 ],\n",
       "       [ 0.77145295, -0.69709227],\n",
       "       [ 1.00549331,  0.38686701],\n",
       "       [-0.74872343, -0.06972957],\n",
       "       [ 1.89948318,  0.79928869],\n",
       "       [-0.87006365,  0.70686285],\n",
       "       [ 1.12856036,  0.33191968],\n",
       "       [ 0.97370054, -0.08631168],\n",
       "       [ 0.89715307,  0.94175457],\n",
       "       [-0.51699811,  0.74457804],\n",
       "       [-0.59385445,  0.46769065],\n",
       "       [-0.46333991,  0.86330772],\n",
       "       [ 0.55039452,  1.16554689],\n",
       "       [-0.60690411,  0.50000529],\n",
       "       [ 0.42598043, -0.3006242 ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "La precisión sobre el dataset de entrenamiento es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = red.score(X_train, y_train)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "La precisión sobre el dataset de prueba es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_test = red.score(X_test, y_test)\n",
    "acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mglearn\n",
    "mglearn.plots.plot_2d_separator(red, X_train, fill=True, alpha=.3)\n",
    "mglearn.discrete_scatter(X_train[:, 0], X_train[:, 1], y_train) \n",
    "plt.xlabel(\"Feature 0\") \n",
    "plt.ylabel(\"Feature 1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ejercicio\n",
    "Resuelva el problema del perceptron con 2 neuronas en la capa oculta. Considere utilizar una función de activación apropiada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X = np.array([[-1, -1], [-1, 1], [1, -1], [1, 1]])\n",
    "Y = np.array([[-1], [1], [1],[-1] ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Pruebe el código utiliznado:\n",
    "1. SGD\n",
    "2. lbfgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "red_xor = MLPClassifier(hidden_layer_sizes=(2,2),\n",
    "                        activation='tanh',\n",
    "                        solver='lbfgs',\n",
    "                        max_iter=1500, verbose=1)\n",
    "#lbfgs / lbfgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Entrenando la red:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leninml/anaconda3/envs/MachineLearning/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(2, 2), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=1500, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_xor.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_xor.score(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1,  1, -1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = red_xor.predict(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y_grafico = [-1, 1, 1, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.scatter(X[:,0],X[:,1], c=y_grafico, cmap=cm_bright)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mglearn.plots.plot_2d_separator(red_xor, X, fill=True, alpha=.3)\n",
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], y_grafico) \n",
    "plt.xlabel(\"Feature 0\") \n",
    "plt.ylabel(\"Feature 1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ejercicios adicionales\n",
    "Resuelva con una arquitectura de red neuronal feed forward multicapa el dataset iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Red Neuronal como Regresión\n",
    "Considere una función $y = x^2-2x+3$. Para el intervalo de $[-5, 5]$ Obtenga 1000 puntos. Puede hacer que la red neuronal reproduzca esta función en el Intervalo propuesto?\n",
    "\n",
    "Que pasa si incrementa el dataset a 2000 muestras?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-5,5, num=2000)\n",
    "# x = np.arange(10)\n",
    "y = x*x-2*x+3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.       , -4.9949975, -4.989995 , ...,  4.989995 ,  4.9949975,\n",
       "        5.       ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = x.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y = y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leninml/anaconda3/envs/MachineLearning/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 102.72146739\n",
      "Iteration 2, loss = 91.67507298\n",
      "Iteration 3, loss = 80.79855813\n",
      "Iteration 4, loss = 70.21359290\n",
      "Iteration 5, loss = 59.52873038\n",
      "Iteration 6, loss = 49.17332621\n",
      "Iteration 7, loss = 39.17911589\n",
      "Iteration 8, loss = 30.05589102\n",
      "Iteration 9, loss = 22.13170099\n",
      "Iteration 10, loss = 15.68461454\n",
      "Iteration 11, loss = 10.80280250\n",
      "Iteration 12, loss = 7.31788942\n",
      "Iteration 13, loss = 5.30866319\n",
      "Iteration 14, loss = 4.26833852\n",
      "Iteration 15, loss = 3.76771028\n",
      "Iteration 16, loss = 3.53851576\n",
      "Iteration 17, loss = 3.42237284\n",
      "Iteration 18, loss = 3.32479950\n",
      "Iteration 19, loss = 3.23269111\n",
      "Iteration 20, loss = 3.14430071\n",
      "Iteration 21, loss = 3.06049025\n",
      "Iteration 22, loss = 2.98391399\n",
      "Iteration 23, loss = 2.90511158\n",
      "Iteration 24, loss = 2.83270154\n",
      "Iteration 25, loss = 2.76281149\n",
      "Iteration 26, loss = 2.69675328\n",
      "Iteration 27, loss = 2.63276435\n",
      "Iteration 28, loss = 2.56992920\n",
      "Iteration 29, loss = 2.50998481\n",
      "Iteration 30, loss = 2.45241838\n",
      "Iteration 31, loss = 2.39688771\n",
      "Iteration 32, loss = 2.34260634\n",
      "Iteration 33, loss = 2.29003072\n",
      "Iteration 34, loss = 2.23855751\n",
      "Iteration 35, loss = 2.19154494\n",
      "Iteration 36, loss = 2.14108414\n",
      "Iteration 37, loss = 2.09733350\n",
      "Iteration 38, loss = 2.05079276\n",
      "Iteration 39, loss = 2.00536804\n",
      "Iteration 40, loss = 1.96142333\n",
      "Iteration 41, loss = 1.92041004\n",
      "Iteration 42, loss = 1.87895965\n",
      "Iteration 43, loss = 1.83968009\n",
      "Iteration 44, loss = 1.80110220\n",
      "Iteration 45, loss = 1.76328102\n",
      "Iteration 46, loss = 1.72733003\n",
      "Iteration 47, loss = 1.69119277\n",
      "Iteration 48, loss = 1.65670389\n",
      "Iteration 49, loss = 1.62334729\n",
      "Iteration 50, loss = 1.59059187\n",
      "Iteration 51, loss = 1.55914786\n",
      "Iteration 52, loss = 1.52830292\n",
      "Iteration 53, loss = 1.49773725\n",
      "Iteration 54, loss = 1.46855568\n",
      "Iteration 55, loss = 1.44150889\n",
      "Iteration 56, loss = 1.41249967\n",
      "Iteration 57, loss = 1.38582988\n",
      "Iteration 58, loss = 1.36058208\n",
      "Iteration 59, loss = 1.33341582\n",
      "Iteration 60, loss = 1.30797419\n",
      "Iteration 61, loss = 1.28269430\n",
      "Iteration 62, loss = 1.25914355\n",
      "Iteration 63, loss = 1.23508937\n",
      "Iteration 64, loss = 1.21231723\n",
      "Iteration 65, loss = 1.18834292\n",
      "Iteration 66, loss = 1.16699686\n",
      "Iteration 67, loss = 1.14366561\n",
      "Iteration 68, loss = 1.12205057\n",
      "Iteration 69, loss = 1.09979041\n",
      "Iteration 70, loss = 1.07911158\n",
      "Iteration 71, loss = 1.05776047\n",
      "Iteration 72, loss = 1.03731743\n",
      "Iteration 73, loss = 1.01666299\n",
      "Iteration 74, loss = 0.99793791\n",
      "Iteration 75, loss = 0.97575707\n",
      "Iteration 76, loss = 0.95726795\n",
      "Iteration 77, loss = 0.93694778\n",
      "Iteration 78, loss = 0.91837142\n",
      "Iteration 79, loss = 0.89892520\n",
      "Iteration 80, loss = 0.88043703\n",
      "Iteration 81, loss = 0.86065399\n",
      "Iteration 82, loss = 0.84295136\n",
      "Iteration 83, loss = 0.82429669\n",
      "Iteration 84, loss = 0.80565979\n",
      "Iteration 85, loss = 0.78805012\n",
      "Iteration 86, loss = 0.77138673\n",
      "Iteration 87, loss = 0.75185955\n",
      "Iteration 88, loss = 0.73565640\n",
      "Iteration 89, loss = 0.71953590\n",
      "Iteration 90, loss = 0.70067858\n",
      "Iteration 91, loss = 0.68436221\n",
      "Iteration 92, loss = 0.66819687\n",
      "Iteration 93, loss = 0.65171251\n",
      "Iteration 94, loss = 0.63594252\n",
      "Iteration 95, loss = 0.62021160\n",
      "Iteration 96, loss = 0.60516413\n",
      "Iteration 97, loss = 0.59038901\n",
      "Iteration 98, loss = 0.57621455\n",
      "Iteration 99, loss = 0.56143158\n",
      "Iteration 100, loss = 0.54675315\n",
      "Iteration 101, loss = 0.53377003\n",
      "Iteration 102, loss = 0.51935108\n",
      "Iteration 103, loss = 0.50684153\n",
      "Iteration 104, loss = 0.49358092\n",
      "Iteration 105, loss = 0.48074202\n",
      "Iteration 106, loss = 0.46846204\n",
      "Iteration 107, loss = 0.45687594\n",
      "Iteration 108, loss = 0.44479298\n",
      "Iteration 109, loss = 0.43373647\n",
      "Iteration 110, loss = 0.42288257\n",
      "Iteration 111, loss = 0.41130332\n",
      "Iteration 112, loss = 0.40172343\n",
      "Iteration 113, loss = 0.39216068\n",
      "Iteration 114, loss = 0.38031346\n",
      "Iteration 115, loss = 0.37095995\n",
      "Iteration 116, loss = 0.36201353\n",
      "Iteration 117, loss = 0.35190584\n",
      "Iteration 118, loss = 0.34250765\n",
      "Iteration 119, loss = 0.33421027\n",
      "Iteration 120, loss = 0.32539846\n",
      "Iteration 121, loss = 0.31715134\n",
      "Iteration 122, loss = 0.30919114\n",
      "Iteration 123, loss = 0.30106225\n",
      "Iteration 124, loss = 0.29419971\n",
      "Iteration 125, loss = 0.28635944\n",
      "Iteration 126, loss = 0.27911136\n",
      "Iteration 127, loss = 0.27188335\n",
      "Iteration 128, loss = 0.26595344\n",
      "Iteration 129, loss = 0.25996664\n",
      "Iteration 130, loss = 0.25171637\n",
      "Iteration 131, loss = 0.24575853\n",
      "Iteration 132, loss = 0.23953071\n",
      "Iteration 133, loss = 0.23380421\n",
      "Iteration 134, loss = 0.22757049\n",
      "Iteration 135, loss = 0.22248892\n",
      "Iteration 136, loss = 0.21626585\n",
      "Iteration 137, loss = 0.21212836\n",
      "Iteration 138, loss = 0.20523178\n",
      "Iteration 139, loss = 0.20071245\n",
      "Iteration 140, loss = 0.19558895\n",
      "Iteration 141, loss = 0.19103498\n",
      "Iteration 142, loss = 0.18608032\n",
      "Iteration 143, loss = 0.18133562\n",
      "Iteration 144, loss = 0.17724838\n",
      "Iteration 145, loss = 0.17288177\n",
      "Iteration 146, loss = 0.16904197\n",
      "Iteration 147, loss = 0.16413811\n",
      "Iteration 148, loss = 0.16009184\n",
      "Iteration 149, loss = 0.15621559\n",
      "Iteration 150, loss = 0.15270345\n",
      "Iteration 151, loss = 0.14869934\n",
      "Iteration 152, loss = 0.14616290\n",
      "Iteration 153, loss = 0.14169750\n",
      "Iteration 154, loss = 0.13818625\n",
      "Iteration 155, loss = 0.13486399\n",
      "Iteration 156, loss = 0.13132768\n",
      "Iteration 157, loss = 0.12833580\n",
      "Iteration 158, loss = 0.12565324\n",
      "Iteration 159, loss = 0.12253017\n",
      "Iteration 160, loss = 0.12000857\n",
      "Iteration 161, loss = 0.11635006\n",
      "Iteration 162, loss = 0.11350800\n",
      "Iteration 163, loss = 0.11131935\n",
      "Iteration 164, loss = 0.10810058\n",
      "Iteration 165, loss = 0.10583669\n",
      "Iteration 166, loss = 0.10295002\n",
      "Iteration 167, loss = 0.10075140\n",
      "Iteration 168, loss = 0.09836778\n",
      "Iteration 169, loss = 0.09613109\n",
      "Iteration 170, loss = 0.09368638\n",
      "Iteration 171, loss = 0.09146311\n",
      "Iteration 172, loss = 0.08914574\n",
      "Iteration 173, loss = 0.08722990\n",
      "Iteration 174, loss = 0.08517794\n",
      "Iteration 175, loss = 0.08347261\n",
      "Iteration 176, loss = 0.08137914\n",
      "Iteration 177, loss = 0.07944792\n",
      "Iteration 178, loss = 0.07774641\n",
      "Iteration 179, loss = 0.07618717\n",
      "Iteration 180, loss = 0.07420839\n",
      "Iteration 181, loss = 0.07235059\n",
      "Iteration 182, loss = 0.07078334\n",
      "Iteration 183, loss = 0.06923895\n",
      "Iteration 184, loss = 0.06755768\n",
      "Iteration 185, loss = 0.06592068\n",
      "Iteration 186, loss = 0.06473508\n",
      "Iteration 187, loss = 0.06348529\n",
      "Iteration 188, loss = 0.06171428\n",
      "Iteration 189, loss = 0.06043116\n",
      "Iteration 190, loss = 0.05921929\n",
      "Iteration 191, loss = 0.05885309\n",
      "Iteration 192, loss = 0.05678889\n",
      "Iteration 193, loss = 0.05524177\n",
      "Iteration 194, loss = 0.05409928\n",
      "Iteration 195, loss = 0.05295601\n",
      "Iteration 196, loss = 0.05204670\n",
      "Iteration 197, loss = 0.05073245\n",
      "Iteration 198, loss = 0.04978785\n",
      "Iteration 199, loss = 0.04870070\n",
      "Iteration 200, loss = 0.04760799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leninml/anaconda3/envs/MachineLearning/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(500,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)\n",
    "red_funcion = MLPRegressor(hidden_layer_sizes=(500,), solver='adam', activation='relu', verbose=1)\n",
    "red_funcion.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9989574284085255"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_funcion.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x_test = np.linspace(-5,5,500)\n",
    "y_real = x_test*x_test-2*x_test+3\n",
    "x_test = x_test.reshape(-1,1)\n",
    "# x_test\n",
    "y_pred = red_funcion.predict(x_test)\n",
    "\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(x_test, y_real, color='blue')\n",
    "plt.plot(x_test, y_pred, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "¿Qué sucede si deseo calcular para un valor fuera del rango como por ejemplo $x=5.5$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_num = 16.\n",
    "y_num = x_num*x_num-2*x_num+3\n",
    "y_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([83.6692473])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_num = np.asarray(x_num)\n",
    "x_num = x_num.reshape(-1,1)\n",
    "y_num_pred = red_funcion.predict(x_num)\n",
    "y_num_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Resolviendo el problema de clasificación del iris dataset\n",
    "Considere el problema de clasificar las flores iris según la longitud y ancho del sépalo y el pétolo. Resuelva este problema utilizando Redes Neuronales Multicapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_dataset = load_iris()\n",
    "print(iris_dataset.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Los primeros 5 datos del dataset son $\\mathbf{\\mathcal{X}}:$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_dataset['data'][0:5,:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Las etiquetas para las **muestras** o **samples** anteriores son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_dataset['target'][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Paso los datos del iris dataset a una variable $\\mathbf{\\mathcal{X}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X = iris_dataset['data']\n",
    "Y = iris_dataset['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Codificando las clases como **ONE HOT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "Y_one_hot = np_utils.to_categorical(Y)\n",
    "Y_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Escalando los valores de $\\mathbf{\\mathcal{X}}$. Sin embargo primero pruebe el entrenamiento sin escalar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La media [5.84333333 3.05733333 3.758      1.19933333]\n",
      "Escalado de X, se muestra primeras 5 filas \n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n",
      "min 0.1\n",
      "max 7.9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "funcion_escalado = scaler.fit(X)\n",
    "X_escalado = X\n",
    "# X_escalado = funcion_escalado.transform(X)\n",
    "print('La media {}'.format(scaler.mean_))\n",
    "print('Escalado de X, se muestra primeras 5 filas \\n{}'.format(X_escalado[0:5,:]))\n",
    "print('min {}'.format(X_escalado.min()))\n",
    "print('max {}'.format(X_escalado.max()))\n",
    "# StandardScaler?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Dividiendo el dataset en train y test. Los datos se deben aleatorizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.2, 2.8, 4.8, 1.8],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [5.4, 3. , 4.5, 1.5]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_escalado, Y_one_hot, test_size=0.2, random_state=2)\n",
    "X_train[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Creando un Modelo de Redes Neuronales Artificiales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "red_iris = MLPClassifier(hidden_layer_sizes=(3,),\n",
    "                        activation='tanh',\n",
    "                        solver='sgd',\n",
    "                        momentum=0.95,\n",
    "                        max_iter=1500, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "Ajuste de Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.72180080\n",
      "Iteration 2, loss = 2.71866401\n",
      "Iteration 3, loss = 2.71408659\n",
      "Iteration 4, loss = 2.70815287\n",
      "Iteration 5, loss = 2.70094656\n",
      "Iteration 6, loss = 2.69255084\n",
      "Iteration 7, loss = 2.68304850\n",
      "Iteration 8, loss = 2.67252214\n",
      "Iteration 9, loss = 2.66105434\n",
      "Iteration 10, loss = 2.64872782\n",
      "Iteration 11, loss = 2.63562552\n",
      "Iteration 12, loss = 2.62183057\n",
      "Iteration 13, loss = 2.60742612\n",
      "Iteration 14, loss = 2.59249500\n",
      "Iteration 15, loss = 2.57711914\n",
      "Iteration 16, loss = 2.56137878\n",
      "Iteration 17, loss = 2.54535152\n",
      "Iteration 18, loss = 2.52911111\n",
      "Iteration 19, loss = 2.51272620\n",
      "Iteration 20, loss = 2.49625906\n",
      "Iteration 21, loss = 2.47976438\n",
      "Iteration 22, loss = 2.46328834\n",
      "Iteration 23, loss = 2.44686792\n",
      "Iteration 24, loss = 2.43053071\n",
      "Iteration 25, loss = 2.41429510\n",
      "Iteration 26, loss = 2.39817099\n",
      "Iteration 27, loss = 2.38216090\n",
      "Iteration 28, loss = 2.36626136\n",
      "Iteration 29, loss = 2.35046465\n",
      "Iteration 30, loss = 2.33476051\n",
      "Iteration 31, loss = 2.31913794\n",
      "Iteration 32, loss = 2.30358671\n",
      "Iteration 33, loss = 2.28809882\n",
      "Iteration 34, loss = 2.27266949\n",
      "Iteration 35, loss = 2.25729788\n",
      "Iteration 36, loss = 2.24198750\n",
      "Iteration 37, loss = 2.22674617\n",
      "Iteration 38, loss = 2.21158581\n",
      "Iteration 39, loss = 2.19652190\n",
      "Iteration 40, loss = 2.18157273\n",
      "Iteration 41, loss = 2.16675864\n",
      "Iteration 42, loss = 2.15210109\n",
      "Iteration 43, loss = 2.13762175\n",
      "Iteration 44, loss = 2.12334172\n",
      "Iteration 45, loss = 2.10928078\n",
      "Iteration 46, loss = 2.09545675\n",
      "Iteration 47, loss = 2.08188505\n",
      "Iteration 48, loss = 2.06857843\n",
      "Iteration 49, loss = 2.05554671\n",
      "Iteration 50, loss = 2.04279687\n",
      "Iteration 51, loss = 2.03033305\n",
      "Iteration 52, loss = 2.01815676\n",
      "Iteration 53, loss = 2.00626717\n",
      "Iteration 54, loss = 1.99466137\n",
      "Iteration 55, loss = 1.98333476\n",
      "Iteration 56, loss = 1.97228134\n",
      "Iteration 57, loss = 1.96149406\n",
      "Iteration 58, loss = 1.95096520\n",
      "Iteration 59, loss = 1.94068657\n",
      "Iteration 60, loss = 1.93064984\n",
      "Iteration 61, loss = 1.92084675\n",
      "Iteration 62, loss = 1.91126928\n",
      "Iteration 63, loss = 1.90190979\n",
      "Iteration 64, loss = 1.89276116\n",
      "Iteration 65, loss = 1.88381681\n",
      "Iteration 66, loss = 1.87507081\n",
      "Iteration 67, loss = 1.86651781\n",
      "Iteration 68, loss = 1.85815306\n",
      "Iteration 69, loss = 1.84997236\n",
      "Iteration 70, loss = 1.84197203\n",
      "Iteration 71, loss = 1.83414876\n",
      "Iteration 72, loss = 1.82649961\n",
      "Iteration 73, loss = 1.81902187\n",
      "Iteration 74, loss = 1.81171299\n",
      "Iteration 75, loss = 1.80457046\n",
      "Iteration 76, loss = 1.79759180\n",
      "Iteration 77, loss = 1.79077440\n",
      "Iteration 78, loss = 1.78411552\n",
      "Iteration 79, loss = 1.77761223\n",
      "Iteration 80, loss = 1.77126135\n",
      "Iteration 81, loss = 1.76505949\n",
      "Iteration 82, loss = 1.75900297\n",
      "Iteration 83, loss = 1.75308791\n",
      "Iteration 84, loss = 1.74731019\n",
      "Iteration 85, loss = 1.74166551\n",
      "Iteration 86, loss = 1.73614942\n",
      "Iteration 87, loss = 1.73075738\n",
      "Iteration 88, loss = 1.72548477\n",
      "Iteration 89, loss = 1.72032699\n",
      "Iteration 90, loss = 1.71527947\n",
      "Iteration 91, loss = 1.71033772\n",
      "Iteration 92, loss = 1.70549737\n",
      "Iteration 93, loss = 1.70075420\n",
      "Iteration 94, loss = 1.69610419\n",
      "Iteration 95, loss = 1.69154349\n",
      "Iteration 96, loss = 1.68706849\n",
      "Iteration 97, loss = 1.68267577\n",
      "Iteration 98, loss = 1.67836215\n",
      "Iteration 99, loss = 1.67412465\n",
      "Iteration 100, loss = 1.66996048\n",
      "Iteration 101, loss = 1.66586707\n",
      "Iteration 102, loss = 1.66184197\n",
      "Iteration 103, loss = 1.65788294\n",
      "Iteration 104, loss = 1.65398782\n",
      "Iteration 105, loss = 1.65015462\n",
      "Iteration 106, loss = 1.64638139\n",
      "Iteration 107, loss = 1.64266632\n",
      "Iteration 108, loss = 1.63900763\n",
      "Iteration 109, loss = 1.63540361\n",
      "Iteration 110, loss = 1.63185258\n",
      "Iteration 111, loss = 1.62835294\n",
      "Iteration 112, loss = 1.62490306\n",
      "Iteration 113, loss = 1.62150140\n",
      "Iteration 114, loss = 1.61814642\n",
      "Iteration 115, loss = 1.61483659\n",
      "Iteration 116, loss = 1.61157045\n",
      "Iteration 117, loss = 1.60834653\n",
      "Iteration 118, loss = 1.60516343\n",
      "Iteration 119, loss = 1.60201977\n",
      "Iteration 120, loss = 1.59891420\n",
      "Iteration 121, loss = 1.59584543\n",
      "Iteration 122, loss = 1.59281221\n",
      "Iteration 123, loss = 1.58981335\n",
      "Iteration 124, loss = 1.58684769\n",
      "Iteration 125, loss = 1.58391414\n",
      "Iteration 126, loss = 1.58101166\n",
      "Iteration 127, loss = 1.57813926\n",
      "Iteration 128, loss = 1.57529600\n",
      "Iteration 129, loss = 1.57248100\n",
      "Iteration 130, loss = 1.56969343\n",
      "Iteration 131, loss = 1.56693248\n",
      "Iteration 132, loss = 1.56419744\n",
      "Iteration 133, loss = 1.56148758\n",
      "Iteration 134, loss = 1.55880226\n",
      "Iteration 135, loss = 1.55614084\n",
      "Iteration 136, loss = 1.55350274\n",
      "Iteration 137, loss = 1.55088740\n",
      "Iteration 138, loss = 1.54829429\n",
      "Iteration 139, loss = 1.54572290\n",
      "Iteration 140, loss = 1.54317274\n",
      "Iteration 141, loss = 1.54064336\n",
      "Iteration 142, loss = 1.53813431\n",
      "Iteration 143, loss = 1.53564517\n",
      "Iteration 144, loss = 1.53317552\n",
      "Iteration 145, loss = 1.53072498\n",
      "Iteration 146, loss = 1.52829315\n",
      "Iteration 147, loss = 1.52587969\n",
      "Iteration 148, loss = 1.52348422\n",
      "Iteration 149, loss = 1.52110641\n",
      "Iteration 150, loss = 1.51874594\n",
      "Iteration 151, loss = 1.51640247\n",
      "Iteration 152, loss = 1.51407572\n",
      "Iteration 153, loss = 1.51176537\n",
      "Iteration 154, loss = 1.50947116\n",
      "Iteration 155, loss = 1.50719280\n",
      "Iteration 156, loss = 1.50493005\n",
      "Iteration 157, loss = 1.50268264\n",
      "Iteration 158, loss = 1.50045034\n",
      "Iteration 159, loss = 1.49823293\n",
      "Iteration 160, loss = 1.49603019\n",
      "Iteration 161, loss = 1.49384190\n",
      "Iteration 162, loss = 1.49166788\n",
      "Iteration 163, loss = 1.48950793\n",
      "Iteration 164, loss = 1.48736187\n",
      "Iteration 165, loss = 1.48522953\n",
      "Iteration 166, loss = 1.48311074\n",
      "Iteration 167, loss = 1.48100536\n",
      "Iteration 168, loss = 1.47891322\n",
      "Iteration 169, loss = 1.47683419\n",
      "Iteration 170, loss = 1.47476812\n",
      "Iteration 171, loss = 1.47271488\n",
      "Iteration 172, loss = 1.47067435\n",
      "Iteration 173, loss = 1.46864640\n",
      "Iteration 174, loss = 1.46663092\n",
      "Iteration 175, loss = 1.46462777\n",
      "Iteration 176, loss = 1.46263687\n",
      "Iteration 177, loss = 1.46065808\n",
      "Iteration 178, loss = 1.45869132\n",
      "Iteration 179, loss = 1.45673647\n",
      "Iteration 180, loss = 1.45479344\n",
      "Iteration 181, loss = 1.45286213\n",
      "Iteration 182, loss = 1.45094243\n",
      "Iteration 183, loss = 1.44903427\n",
      "Iteration 184, loss = 1.44713754\n",
      "Iteration 185, loss = 1.44525215\n",
      "Iteration 186, loss = 1.44337803\n",
      "Iteration 187, loss = 1.44151507\n",
      "Iteration 188, loss = 1.43966321\n",
      "Iteration 189, loss = 1.43782234\n",
      "Iteration 190, loss = 1.43599240\n",
      "Iteration 191, loss = 1.43417329\n",
      "Iteration 192, loss = 1.43236496\n",
      "Iteration 193, loss = 1.43056730\n",
      "Iteration 194, loss = 1.42878026\n",
      "Iteration 195, loss = 1.42700375\n",
      "Iteration 196, loss = 1.42523771\n",
      "Iteration 197, loss = 1.42348205\n",
      "Iteration 198, loss = 1.42173671\n",
      "Iteration 199, loss = 1.42000162\n",
      "Iteration 200, loss = 1.41827671\n",
      "Iteration 201, loss = 1.41656191\n",
      "Iteration 202, loss = 1.41485715\n",
      "Iteration 203, loss = 1.41316238\n",
      "Iteration 204, loss = 1.41147751\n",
      "Iteration 205, loss = 1.40980249\n",
      "Iteration 206, loss = 1.40813725\n",
      "Iteration 207, loss = 1.40648174\n",
      "Iteration 208, loss = 1.40483588\n",
      "Iteration 209, loss = 1.40319962\n",
      "Iteration 210, loss = 1.40157289\n",
      "Iteration 211, loss = 1.39995563\n",
      "Iteration 212, loss = 1.39834778\n",
      "Iteration 213, loss = 1.39674929\n",
      "Iteration 214, loss = 1.39516008\n",
      "Iteration 215, loss = 1.39358011\n",
      "Iteration 216, loss = 1.39200932\n",
      "Iteration 217, loss = 1.39044763\n",
      "Iteration 218, loss = 1.38889501\n",
      "Iteration 219, loss = 1.38735138\n",
      "Iteration 220, loss = 1.38581669\n",
      "Iteration 221, loss = 1.38429089\n",
      "Iteration 222, loss = 1.38277392\n",
      "Iteration 223, loss = 1.38126571\n",
      "Iteration 224, loss = 1.37976622\n",
      "Iteration 225, loss = 1.37827539\n",
      "Iteration 226, loss = 1.37679317\n",
      "Iteration 227, loss = 1.37531949\n",
      "Iteration 228, loss = 1.37385430\n",
      "Iteration 229, loss = 1.37239755\n",
      "Iteration 230, loss = 1.37094919\n",
      "Iteration 231, loss = 1.36950915\n",
      "Iteration 232, loss = 1.36807739\n",
      "Iteration 233, loss = 1.36665385\n",
      "Iteration 234, loss = 1.36523848\n",
      "Iteration 235, loss = 1.36383122\n",
      "Iteration 236, loss = 1.36243203\n",
      "Iteration 237, loss = 1.36104085\n",
      "Iteration 238, loss = 1.35965762\n",
      "Iteration 239, loss = 1.35828230\n",
      "Iteration 240, loss = 1.35691484\n",
      "Iteration 241, loss = 1.35555518\n",
      "Iteration 242, loss = 1.35420327\n",
      "Iteration 243, loss = 1.35285906\n",
      "Iteration 244, loss = 1.35152250\n",
      "Iteration 245, loss = 1.35019354\n",
      "Iteration 246, loss = 1.34887213\n",
      "Iteration 247, loss = 1.34755822\n",
      "Iteration 248, loss = 1.34625176\n",
      "Iteration 249, loss = 1.34495271\n",
      "Iteration 250, loss = 1.34366100\n",
      "Iteration 251, loss = 1.34237660\n",
      "Iteration 252, loss = 1.34109945\n",
      "Iteration 253, loss = 1.33982951\n",
      "Iteration 254, loss = 1.33856672\n",
      "Iteration 255, loss = 1.33731105\n",
      "Iteration 256, loss = 1.33606244\n",
      "Iteration 257, loss = 1.33482084\n",
      "Iteration 258, loss = 1.33358622\n",
      "Iteration 259, loss = 1.33235851\n",
      "Iteration 260, loss = 1.33113768\n",
      "Iteration 261, loss = 1.32992368\n",
      "Iteration 262, loss = 1.32871647\n",
      "Iteration 263, loss = 1.32751599\n",
      "Iteration 264, loss = 1.32632220\n",
      "Iteration 265, loss = 1.32513506\n",
      "Iteration 266, loss = 1.32395452\n",
      "Iteration 267, loss = 1.32278054\n",
      "Iteration 268, loss = 1.32161308\n",
      "Iteration 269, loss = 1.32045208\n",
      "Iteration 270, loss = 1.31929750\n",
      "Iteration 271, loss = 1.31814931\n",
      "Iteration 272, loss = 1.31700746\n",
      "Iteration 273, loss = 1.31587190\n",
      "Iteration 274, loss = 1.31474259\n",
      "Iteration 275, loss = 1.31361950\n",
      "Iteration 276, loss = 1.31250257\n",
      "Iteration 277, loss = 1.31139176\n",
      "Iteration 278, loss = 1.31028704\n",
      "Iteration 279, loss = 1.30918836\n",
      "Iteration 280, loss = 1.30809568\n",
      "Iteration 281, loss = 1.30700897\n",
      "Iteration 282, loss = 1.30592817\n",
      "Iteration 283, loss = 1.30485325\n",
      "Iteration 284, loss = 1.30378417\n",
      "Iteration 285, loss = 1.30272089\n",
      "Iteration 286, loss = 1.30166337\n",
      "Iteration 287, loss = 1.30061156\n",
      "Iteration 288, loss = 1.29956544\n",
      "Iteration 289, loss = 1.29852496\n",
      "Iteration 290, loss = 1.29749009\n",
      "Iteration 291, loss = 1.29646078\n",
      "Iteration 292, loss = 1.29543699\n",
      "Iteration 293, loss = 1.29441870\n",
      "Iteration 294, loss = 1.29340586\n",
      "Iteration 295, loss = 1.29239843\n",
      "Iteration 296, loss = 1.29139638\n",
      "Iteration 297, loss = 1.29039967\n",
      "Iteration 298, loss = 1.28940826\n",
      "Iteration 299, loss = 1.28842213\n",
      "Iteration 300, loss = 1.28744122\n",
      "Iteration 301, loss = 1.28646551\n",
      "Iteration 302, loss = 1.28549496\n",
      "Iteration 303, loss = 1.28452954\n",
      "Iteration 304, loss = 1.28356921\n",
      "Iteration 305, loss = 1.28261393\n",
      "Iteration 306, loss = 1.28166368\n",
      "Iteration 307, loss = 1.28071841\n",
      "Iteration 308, loss = 1.27977810\n",
      "Iteration 309, loss = 1.27884270\n",
      "Iteration 310, loss = 1.27791219\n",
      "Iteration 311, loss = 1.27698653\n",
      "Iteration 312, loss = 1.27606570\n",
      "Iteration 313, loss = 1.27514965\n",
      "Iteration 314, loss = 1.27423835\n",
      "Iteration 315, loss = 1.27333177\n",
      "Iteration 316, loss = 1.27242989\n",
      "Iteration 317, loss = 1.27153266\n",
      "Iteration 318, loss = 1.27064006\n",
      "Iteration 319, loss = 1.26975206\n",
      "Iteration 320, loss = 1.26886861\n",
      "Iteration 321, loss = 1.26798971\n",
      "Iteration 322, loss = 1.26711530\n",
      "Iteration 323, loss = 1.26624537\n",
      "Iteration 324, loss = 1.26537987\n",
      "Iteration 325, loss = 1.26451879\n",
      "Iteration 326, loss = 1.26366209\n",
      "Iteration 327, loss = 1.26280974\n",
      "Iteration 328, loss = 1.26196172\n",
      "Iteration 329, loss = 1.26111799\n",
      "Iteration 330, loss = 1.26027853\n",
      "Iteration 331, loss = 1.25944330\n",
      "Iteration 332, loss = 1.25861227\n",
      "Iteration 333, loss = 1.25778543\n",
      "Iteration 334, loss = 1.25696274\n",
      "Iteration 335, loss = 1.25614418\n",
      "Iteration 336, loss = 1.25532971\n",
      "Iteration 337, loss = 1.25451930\n",
      "Iteration 338, loss = 1.25371294\n",
      "Iteration 339, loss = 1.25291060\n",
      "Iteration 340, loss = 1.25211224\n",
      "Iteration 341, loss = 1.25131784\n",
      "Iteration 342, loss = 1.25052738\n",
      "Iteration 343, loss = 1.24974083\n",
      "Iteration 344, loss = 1.24895815\n",
      "Iteration 345, loss = 1.24817934\n",
      "Iteration 346, loss = 1.24740436\n",
      "Iteration 347, loss = 1.24663318\n",
      "Iteration 348, loss = 1.24586578\n",
      "Iteration 349, loss = 1.24510214\n",
      "Iteration 350, loss = 1.24434223\n",
      "Iteration 351, loss = 1.24358602\n",
      "Iteration 352, loss = 1.24283350\n",
      "Iteration 353, loss = 1.24208463\n",
      "Iteration 354, loss = 1.24133940\n",
      "Iteration 355, loss = 1.24059778\n",
      "Iteration 356, loss = 1.23985974\n",
      "Iteration 357, loss = 1.23912526\n",
      "Iteration 358, loss = 1.23839433\n",
      "Iteration 359, loss = 1.23766691\n",
      "Iteration 360, loss = 1.23694298\n",
      "Iteration 361, loss = 1.23622252\n",
      "Iteration 362, loss = 1.23550551\n",
      "Iteration 363, loss = 1.23479192\n",
      "Iteration 364, loss = 1.23408173\n",
      "Iteration 365, loss = 1.23337493\n",
      "Iteration 366, loss = 1.23267148\n",
      "Iteration 367, loss = 1.23197137\n",
      "Iteration 368, loss = 1.23127458\n",
      "Iteration 369, loss = 1.23058107\n",
      "Iteration 370, loss = 1.22989084\n",
      "Iteration 371, loss = 1.22920386\n",
      "Iteration 372, loss = 1.22852011\n",
      "Iteration 373, loss = 1.22783957\n",
      "Iteration 374, loss = 1.22716222\n",
      "Iteration 375, loss = 1.22648804\n",
      "Iteration 376, loss = 1.22581700\n",
      "Iteration 377, loss = 1.22514909\n",
      "Iteration 378, loss = 1.22448429\n",
      "Iteration 379, loss = 1.22382257\n",
      "Iteration 380, loss = 1.22316392\n",
      "Iteration 381, loss = 1.22250832\n",
      "Iteration 382, loss = 1.22185575\n",
      "Iteration 383, loss = 1.22120619\n",
      "Iteration 384, loss = 1.22055962\n",
      "Iteration 385, loss = 1.21991602\n",
      "Iteration 386, loss = 1.21927537\n",
      "Iteration 387, loss = 1.21863765\n",
      "Iteration 388, loss = 1.21800285\n",
      "Iteration 389, loss = 1.21737095\n",
      "Iteration 390, loss = 1.21674192\n",
      "Iteration 391, loss = 1.21611575\n",
      "Iteration 392, loss = 1.21549243\n",
      "Iteration 393, loss = 1.21487193\n",
      "Iteration 394, loss = 1.21425423\n",
      "Iteration 395, loss = 1.21363932\n",
      "Iteration 396, loss = 1.21302719\n",
      "Iteration 397, loss = 1.21241781\n",
      "Iteration 398, loss = 1.21181116\n",
      "Iteration 399, loss = 1.21120723\n",
      "Iteration 400, loss = 1.21060601\n",
      "Iteration 401, loss = 1.21000747\n",
      "Iteration 402, loss = 1.20941160\n",
      "Iteration 403, loss = 1.20881838\n",
      "Iteration 404, loss = 1.20822780\n",
      "Iteration 405, loss = 1.20763984\n",
      "Iteration 406, loss = 1.20705448\n",
      "Iteration 407, loss = 1.20647170\n",
      "Iteration 408, loss = 1.20589150\n",
      "Iteration 409, loss = 1.20531385\n",
      "Iteration 410, loss = 1.20473875\n",
      "Iteration 411, loss = 1.20416616\n",
      "Iteration 412, loss = 1.20359608\n",
      "Iteration 413, loss = 1.20302850\n",
      "Iteration 414, loss = 1.20246339\n",
      "Iteration 415, loss = 1.20190075\n",
      "Iteration 416, loss = 1.20134055\n",
      "Iteration 417, loss = 1.20078278\n",
      "Iteration 418, loss = 1.20022743\n",
      "Iteration 419, loss = 1.19967448\n",
      "Iteration 420, loss = 1.19912393\n",
      "Iteration 421, loss = 1.19857574\n",
      "Iteration 422, loss = 1.19802991\n",
      "Iteration 423, loss = 1.19748643\n",
      "Iteration 424, loss = 1.19694527\n",
      "Iteration 425, loss = 1.19640644\n",
      "Iteration 426, loss = 1.19586990\n",
      "Iteration 427, loss = 1.19533565\n",
      "Iteration 428, loss = 1.19480368\n",
      "Iteration 429, loss = 1.19427397\n",
      "Iteration 430, loss = 1.19374650\n",
      "Iteration 431, loss = 1.19322127\n",
      "Iteration 432, loss = 1.19269826\n",
      "Iteration 433, loss = 1.19217745\n",
      "Iteration 434, loss = 1.19165884\n",
      "Iteration 435, loss = 1.19114241\n",
      "Iteration 436, loss = 1.19062814\n",
      "Iteration 437, loss = 1.19011603\n",
      "Iteration 438, loss = 1.18960606\n",
      "Iteration 439, loss = 1.18909822\n",
      "Iteration 440, loss = 1.18859249\n",
      "Iteration 441, loss = 1.18808887\n",
      "Iteration 442, loss = 1.18758734\n",
      "Iteration 443, loss = 1.18708789\n",
      "Iteration 444, loss = 1.18659050\n",
      "Iteration 445, loss = 1.18609517\n",
      "Iteration 446, loss = 1.18560188\n",
      "Iteration 447, loss = 1.18511062\n",
      "Iteration 448, loss = 1.18462137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 449, loss = 1.18413413\n",
      "Iteration 450, loss = 1.18364889\n",
      "Iteration 451, loss = 1.18316563\n",
      "Iteration 452, loss = 1.18268434\n",
      "Iteration 453, loss = 1.18220500\n",
      "Iteration 454, loss = 1.18172762\n",
      "Iteration 455, loss = 1.18125217\n",
      "Iteration 456, loss = 1.18077865\n",
      "Iteration 457, loss = 1.18030703\n",
      "Iteration 458, loss = 1.17983733\n",
      "Iteration 459, loss = 1.17936951\n",
      "Iteration 460, loss = 1.17890357\n",
      "Iteration 461, loss = 1.17843951\n",
      "Iteration 462, loss = 1.17797730\n",
      "Iteration 463, loss = 1.17751694\n",
      "Iteration 464, loss = 1.17705841\n",
      "Iteration 465, loss = 1.17660172\n",
      "Iteration 466, loss = 1.17614684\n",
      "Iteration 467, loss = 1.17569376\n",
      "Iteration 468, loss = 1.17524248\n",
      "Iteration 469, loss = 1.17479298\n",
      "Iteration 470, loss = 1.17434526\n",
      "Iteration 471, loss = 1.17389930\n",
      "Iteration 472, loss = 1.17345510\n",
      "Iteration 473, loss = 1.17301264\n",
      "Iteration 474, loss = 1.17257192\n",
      "Iteration 475, loss = 1.17213292\n",
      "Iteration 476, loss = 1.17169563\n",
      "Iteration 477, loss = 1.17126005\n",
      "Iteration 478, loss = 1.17082616\n",
      "Iteration 479, loss = 1.17039396\n",
      "Iteration 480, loss = 1.16996343\n",
      "Iteration 481, loss = 1.16953457\n",
      "Iteration 482, loss = 1.16910736\n",
      "Iteration 483, loss = 1.16868181\n",
      "Iteration 484, loss = 1.16825789\n",
      "Iteration 485, loss = 1.16783560\n",
      "Iteration 486, loss = 1.16741492\n",
      "Iteration 487, loss = 1.16699586\n",
      "Iteration 488, loss = 1.16657840\n",
      "Iteration 489, loss = 1.16616254\n",
      "Iteration 490, loss = 1.16574825\n",
      "Iteration 491, loss = 1.16533554\n",
      "Iteration 492, loss = 1.16492440\n",
      "Iteration 493, loss = 1.16451481\n",
      "Iteration 494, loss = 1.16410677\n",
      "Iteration 495, loss = 1.16370027\n",
      "Iteration 496, loss = 1.16329530\n",
      "Iteration 497, loss = 1.16289185\n",
      "Iteration 498, loss = 1.16248991\n",
      "Iteration 499, loss = 1.16208948\n",
      "Iteration 500, loss = 1.16169055\n",
      "Iteration 501, loss = 1.16129311\n",
      "Iteration 502, loss = 1.16089715\n",
      "Iteration 503, loss = 1.16050265\n",
      "Iteration 504, loss = 1.16010963\n",
      "Iteration 505, loss = 1.15971806\n",
      "Iteration 506, loss = 1.15932793\n",
      "Iteration 507, loss = 1.15893925\n",
      "Iteration 508, loss = 1.15855200\n",
      "Iteration 509, loss = 1.15816617\n",
      "Iteration 510, loss = 1.15778176\n",
      "Iteration 511, loss = 1.15739876\n",
      "Iteration 512, loss = 1.15701715\n",
      "Iteration 513, loss = 1.15663694\n",
      "Iteration 514, loss = 1.15625812\n",
      "Iteration 515, loss = 1.15588067\n",
      "Iteration 516, loss = 1.15550460\n",
      "Iteration 517, loss = 1.15512988\n",
      "Iteration 518, loss = 1.15475652\n",
      "Iteration 519, loss = 1.15438451\n",
      "Iteration 520, loss = 1.15401384\n",
      "Iteration 521, loss = 1.15364451\n",
      "Iteration 522, loss = 1.15327650\n",
      "Iteration 523, loss = 1.15290981\n",
      "Iteration 524, loss = 1.15254443\n",
      "Iteration 525, loss = 1.15218035\n",
      "Iteration 526, loss = 1.15181757\n",
      "Iteration 527, loss = 1.15145609\n",
      "Iteration 528, loss = 1.15109588\n",
      "Iteration 529, loss = 1.15073696\n",
      "Iteration 530, loss = 1.15037930\n",
      "Iteration 531, loss = 1.15002291\n",
      "Iteration 532, loss = 1.14966777\n",
      "Iteration 533, loss = 1.14931388\n",
      "Iteration 534, loss = 1.14896123\n",
      "Iteration 535, loss = 1.14860982\n",
      "Iteration 536, loss = 1.14825964\n",
      "Iteration 537, loss = 1.14791069\n",
      "Iteration 538, loss = 1.14756295\n",
      "Iteration 539, loss = 1.14721641\n",
      "Iteration 540, loss = 1.14687109\n",
      "Iteration 541, loss = 1.14652696\n",
      "Iteration 542, loss = 1.14618402\n",
      "Iteration 543, loss = 1.14584226\n",
      "Iteration 544, loss = 1.14550168\n",
      "Iteration 545, loss = 1.14516227\n",
      "Iteration 546, loss = 1.14482403\n",
      "Iteration 547, loss = 1.14448695\n",
      "Iteration 548, loss = 1.14415102\n",
      "Iteration 549, loss = 1.14381624\n",
      "Iteration 550, loss = 1.14348260\n",
      "Iteration 551, loss = 1.14315010\n",
      "Iteration 552, loss = 1.14281872\n",
      "Iteration 553, loss = 1.14248847\n",
      "Iteration 554, loss = 1.14215933\n",
      "Iteration 555, loss = 1.14183131\n",
      "Iteration 556, loss = 1.14150439\n",
      "Iteration 557, loss = 1.14117857\n",
      "Iteration 558, loss = 1.14085384\n",
      "Iteration 559, loss = 1.14053021\n",
      "Iteration 560, loss = 1.14020765\n",
      "Iteration 561, loss = 1.13988617\n",
      "Iteration 562, loss = 1.13956577\n",
      "Iteration 563, loss = 1.13924643\n",
      "Iteration 564, loss = 1.13892815\n",
      "Iteration 565, loss = 1.13861092\n",
      "Iteration 566, loss = 1.13829474\n",
      "Iteration 567, loss = 1.13797961\n",
      "Iteration 568, loss = 1.13766551\n",
      "Iteration 569, loss = 1.13735245\n",
      "Iteration 570, loss = 1.13704041\n",
      "Iteration 571, loss = 1.13672940\n",
      "Iteration 572, loss = 1.13641940\n",
      "Iteration 573, loss = 1.13611042\n",
      "Iteration 574, loss = 1.13580244\n",
      "Iteration 575, loss = 1.13549546\n",
      "Iteration 576, loss = 1.13518948\n",
      "Iteration 577, loss = 1.13488449\n",
      "Iteration 578, loss = 1.13458048\n",
      "Iteration 579, loss = 1.13427745\n",
      "Iteration 580, loss = 1.13397541\n",
      "Iteration 581, loss = 1.13367433\n",
      "Iteration 582, loss = 1.13337421\n",
      "Iteration 583, loss = 1.13307506\n",
      "Iteration 584, loss = 1.13277686\n",
      "Iteration 585, loss = 1.13247962\n",
      "Iteration 586, loss = 1.13218331\n",
      "Iteration 587, loss = 1.13188795\n",
      "Iteration 588, loss = 1.13159353\n",
      "Iteration 589, loss = 1.13130004\n",
      "Iteration 590, loss = 1.13100747\n",
      "Iteration 591, loss = 1.13071583\n",
      "Iteration 592, loss = 1.13042510\n",
      "Iteration 593, loss = 1.13013529\n",
      "Iteration 594, loss = 1.12984638\n",
      "Iteration 595, loss = 1.12955838\n",
      "Iteration 596, loss = 1.12927127\n",
      "Iteration 597, loss = 1.12898506\n",
      "Iteration 598, loss = 1.12869974\n",
      "Iteration 599, loss = 1.12841531\n",
      "Iteration 600, loss = 1.12813175\n",
      "Iteration 601, loss = 1.12784907\n",
      "Iteration 602, loss = 1.12756726\n",
      "Iteration 603, loss = 1.12728632\n",
      "Iteration 604, loss = 1.12700624\n",
      "Iteration 605, loss = 1.12672702\n",
      "Iteration 606, loss = 1.12644866\n",
      "Iteration 607, loss = 1.12617114\n",
      "Iteration 608, loss = 1.12589447\n",
      "Iteration 609, loss = 1.12561864\n",
      "Iteration 610, loss = 1.12534365\n",
      "Iteration 611, loss = 1.12506948\n",
      "Iteration 612, loss = 1.12479615\n",
      "Iteration 613, loss = 1.12452364\n",
      "Iteration 614, loss = 1.12425196\n",
      "Iteration 615, loss = 1.12398108\n",
      "Iteration 616, loss = 1.12371102\n",
      "Iteration 617, loss = 1.12344177\n",
      "Iteration 618, loss = 1.12317332\n",
      "Iteration 619, loss = 1.12290567\n",
      "Iteration 620, loss = 1.12263882\n",
      "Iteration 621, loss = 1.12237275\n",
      "Iteration 622, loss = 1.12210748\n",
      "Iteration 623, loss = 1.12184299\n",
      "Iteration 624, loss = 1.12157927\n",
      "Iteration 625, loss = 1.12131634\n",
      "Iteration 626, loss = 1.12105417\n",
      "Iteration 627, loss = 1.12079278\n",
      "Iteration 628, loss = 1.12053214\n",
      "Iteration 629, loss = 1.12027227\n",
      "Iteration 630, loss = 1.12001315\n",
      "Iteration 631, loss = 1.11975479\n",
      "Iteration 632, loss = 1.11949717\n",
      "Iteration 633, loss = 1.11924030\n",
      "Iteration 634, loss = 1.11898418\n",
      "Iteration 635, loss = 1.11872878\n",
      "Iteration 636, loss = 1.11847413\n",
      "Iteration 637, loss = 1.11822020\n",
      "Iteration 638, loss = 1.11796700\n",
      "Iteration 639, loss = 1.11771452\n",
      "Iteration 640, loss = 1.11746276\n",
      "Iteration 641, loss = 1.11721171\n",
      "Iteration 642, loss = 1.11696138\n",
      "Iteration 643, loss = 1.11671176\n",
      "Iteration 644, loss = 1.11646284\n",
      "Iteration 645, loss = 1.11621462\n",
      "Iteration 646, loss = 1.11596710\n",
      "Iteration 647, loss = 1.11572028\n",
      "Iteration 648, loss = 1.11547414\n",
      "Iteration 649, loss = 1.11522869\n",
      "Iteration 650, loss = 1.11498393\n",
      "Iteration 651, loss = 1.11473985\n",
      "Iteration 652, loss = 1.11449644\n",
      "Iteration 653, loss = 1.11425371\n",
      "Iteration 654, loss = 1.11401164\n",
      "Iteration 655, loss = 1.11377024\n",
      "Iteration 656, loss = 1.11352951\n",
      "Iteration 657, loss = 1.11328944\n",
      "Iteration 658, loss = 1.11305002\n",
      "Iteration 659, loss = 1.11281126\n",
      "Iteration 660, loss = 1.11257314\n",
      "Iteration 661, loss = 1.11233568\n",
      "Iteration 662, loss = 1.11209885\n",
      "Iteration 663, loss = 1.11186267\n",
      "Iteration 664, loss = 1.11162713\n",
      "Iteration 665, loss = 1.11139221\n",
      "Iteration 666, loss = 1.11115793\n",
      "Iteration 667, loss = 1.11092428\n",
      "Iteration 668, loss = 1.11069125\n",
      "Iteration 669, loss = 1.11045884\n",
      "Iteration 670, loss = 1.11022705\n",
      "Iteration 671, loss = 1.10999587\n",
      "Iteration 672, loss = 1.10976531\n",
      "Iteration 673, loss = 1.10953535\n",
      "Iteration 674, loss = 1.10930600\n",
      "Iteration 675, loss = 1.10907725\n",
      "Iteration 676, loss = 1.10884910\n",
      "Iteration 677, loss = 1.10862155\n",
      "Iteration 678, loss = 1.10839459\n",
      "Iteration 679, loss = 1.10816822\n",
      "Iteration 680, loss = 1.10794243\n",
      "Iteration 681, loss = 1.10771724\n",
      "Iteration 682, loss = 1.10749262\n",
      "Iteration 683, loss = 1.10726858\n",
      "Iteration 684, loss = 1.10704511\n",
      "Iteration 685, loss = 1.10682222\n",
      "Iteration 686, loss = 1.10659990\n",
      "Iteration 687, loss = 1.10637814\n",
      "Iteration 688, loss = 1.10615695\n",
      "Iteration 689, loss = 1.10593632\n",
      "Iteration 690, loss = 1.10571624\n",
      "Iteration 691, loss = 1.10549672\n",
      "Iteration 692, loss = 1.10527775\n",
      "Iteration 693, loss = 1.10505933\n",
      "Iteration 694, loss = 1.10484146\n",
      "Iteration 695, loss = 1.10462413\n",
      "Iteration 696, loss = 1.10440734\n",
      "Iteration 697, loss = 1.10419109\n",
      "Iteration 698, loss = 1.10397537\n",
      "Iteration 699, loss = 1.10376018\n",
      "Iteration 700, loss = 1.10354553\n",
      "Iteration 701, loss = 1.10333140\n",
      "Iteration 702, loss = 1.10311779\n",
      "Iteration 703, loss = 1.10290471\n",
      "Iteration 704, loss = 1.10269214\n",
      "Iteration 705, loss = 1.10248009\n",
      "Iteration 706, loss = 1.10226855\n",
      "Iteration 707, loss = 1.10205752\n",
      "Iteration 708, loss = 1.10184700\n",
      "Iteration 709, loss = 1.10163699\n",
      "Iteration 710, loss = 1.10142747\n",
      "Iteration 711, loss = 1.10121846\n",
      "Iteration 712, loss = 1.10100994\n",
      "Iteration 713, loss = 1.10080192\n",
      "Iteration 714, loss = 1.10059438\n",
      "Iteration 715, loss = 1.10038734\n",
      "Iteration 716, loss = 1.10018078\n",
      "Iteration 717, loss = 1.09997471\n",
      "Iteration 718, loss = 1.09976912\n",
      "Iteration 719, loss = 1.09956400\n",
      "Iteration 720, loss = 1.09935936\n",
      "Iteration 721, loss = 1.09915520\n",
      "Iteration 722, loss = 1.09895150\n",
      "Iteration 723, loss = 1.09874827\n",
      "Iteration 724, loss = 1.09854551\n",
      "Iteration 725, loss = 1.09834321\n",
      "Iteration 726, loss = 1.09814137\n",
      "Iteration 727, loss = 1.09793999\n",
      "Iteration 728, loss = 1.09773907\n",
      "Iteration 729, loss = 1.09753859\n",
      "Iteration 730, loss = 1.09733857\n",
      "Iteration 731, loss = 1.09713899\n",
      "Iteration 732, loss = 1.09693987\n",
      "Iteration 733, loss = 1.09674118\n",
      "Iteration 734, loss = 1.09654293\n",
      "Iteration 735, loss = 1.09634512\n",
      "Iteration 736, loss = 1.09614775\n",
      "Iteration 737, loss = 1.09595081\n",
      "Iteration 738, loss = 1.09575430\n",
      "Iteration 739, loss = 1.09555822\n",
      "Iteration 740, loss = 1.09536256\n",
      "Iteration 741, loss = 1.09516733\n",
      "Iteration 742, loss = 1.09497252\n",
      "Iteration 743, loss = 1.09477812\n",
      "Iteration 744, loss = 1.09458415\n",
      "Iteration 745, loss = 1.09439058\n",
      "Iteration 746, loss = 1.09419743\n",
      "Iteration 747, loss = 1.09400468\n",
      "Iteration 748, loss = 1.09381235\n",
      "Iteration 749, loss = 1.09362041\n",
      "Iteration 750, loss = 1.09342888\n",
      "Iteration 751, loss = 1.09323775\n",
      "Iteration 752, loss = 1.09304701\n",
      "Iteration 753, loss = 1.09285667\n",
      "Iteration 754, loss = 1.09266672\n",
      "Iteration 755, loss = 1.09247716\n",
      "Iteration 756, loss = 1.09228799\n",
      "Iteration 757, loss = 1.09209920\n",
      "Iteration 758, loss = 1.09191080\n",
      "Iteration 759, loss = 1.09172278\n",
      "Iteration 760, loss = 1.09153513\n",
      "Iteration 761, loss = 1.09134786\n",
      "Iteration 762, loss = 1.09116097\n",
      "Iteration 763, loss = 1.09097445\n",
      "Iteration 764, loss = 1.09078829\n",
      "Iteration 765, loss = 1.09060250\n",
      "Iteration 766, loss = 1.09041708\n",
      "Iteration 767, loss = 1.09023202\n",
      "Iteration 768, loss = 1.09004732\n",
      "Iteration 769, loss = 1.08986298\n",
      "Iteration 770, loss = 1.08967899\n",
      "Iteration 771, loss = 1.08949536\n",
      "Iteration 772, loss = 1.08931207\n",
      "Iteration 773, loss = 1.08912914\n",
      "Iteration 774, loss = 1.08894655\n",
      "Iteration 775, loss = 1.08876431\n",
      "Iteration 776, loss = 1.08858241\n",
      "Iteration 777, loss = 1.08840084\n",
      "Iteration 778, loss = 1.08821962\n",
      "Iteration 779, loss = 1.08803873\n",
      "Iteration 780, loss = 1.08785818\n",
      "Iteration 781, loss = 1.08767795\n",
      "Iteration 782, loss = 1.08749806\n",
      "Iteration 783, loss = 1.08731849\n",
      "Iteration 784, loss = 1.08713924\n",
      "Iteration 785, loss = 1.08696032\n",
      "Iteration 786, loss = 1.08678172\n",
      "Iteration 787, loss = 1.08660343\n",
      "Iteration 788, loss = 1.08642546\n",
      "Iteration 789, loss = 1.08624781\n",
      "Iteration 790, loss = 1.08607046\n",
      "Iteration 791, loss = 1.08589343\n",
      "Iteration 792, loss = 1.08571670\n",
      "Iteration 793, loss = 1.08554027\n",
      "Iteration 794, loss = 1.08536415\n",
      "Iteration 795, loss = 1.08518833\n",
      "Iteration 796, loss = 1.08501281\n",
      "Iteration 797, loss = 1.08483758\n",
      "Iteration 798, loss = 1.08466265\n",
      "Iteration 799, loss = 1.08448801\n",
      "Iteration 800, loss = 1.08431366\n",
      "Iteration 801, loss = 1.08413959\n",
      "Iteration 802, loss = 1.08396581\n",
      "Iteration 803, loss = 1.08379232\n",
      "Iteration 804, loss = 1.08361911\n",
      "Iteration 805, loss = 1.08344617\n",
      "Iteration 806, loss = 1.08327351\n",
      "Iteration 807, loss = 1.08310113\n",
      "Iteration 808, loss = 1.08292902\n",
      "Iteration 809, loss = 1.08275718\n",
      "Iteration 810, loss = 1.08258560\n",
      "Iteration 811, loss = 1.08241430\n",
      "Iteration 812, loss = 1.08224326\n",
      "Iteration 813, loss = 1.08207248\n",
      "Iteration 814, loss = 1.08190196\n",
      "Iteration 815, loss = 1.08173170\n",
      "Iteration 816, loss = 1.08156169\n",
      "Iteration 817, loss = 1.08139194\n",
      "Iteration 818, loss = 1.08122244\n",
      "Iteration 819, loss = 1.08105318\n",
      "Iteration 820, loss = 1.08088418\n",
      "Iteration 821, loss = 1.08071542\n",
      "Iteration 822, loss = 1.08054690\n",
      "Iteration 823, loss = 1.08037863\n",
      "Iteration 824, loss = 1.08021059\n",
      "Iteration 825, loss = 1.08004279\n",
      "Iteration 826, loss = 1.07987523\n",
      "Iteration 827, loss = 1.07970790\n",
      "Iteration 828, loss = 1.07954080\n",
      "Iteration 829, loss = 1.07937392\n",
      "Iteration 830, loss = 1.07920728\n",
      "Iteration 831, loss = 1.07904086\n",
      "Iteration 832, loss = 1.07887466\n",
      "Iteration 833, loss = 1.07870868\n",
      "Iteration 834, loss = 1.07854292\n",
      "Iteration 835, loss = 1.07837737\n",
      "Iteration 836, loss = 1.07821204\n",
      "Iteration 837, loss = 1.07804692\n",
      "Iteration 838, loss = 1.07788201\n",
      "Iteration 839, loss = 1.07771731\n",
      "Iteration 840, loss = 1.07755282\n",
      "Iteration 841, loss = 1.07738853\n",
      "Iteration 842, loss = 1.07722444\n",
      "Iteration 843, loss = 1.07706055\n",
      "Iteration 844, loss = 1.07689686\n",
      "Iteration 845, loss = 1.07673336\n",
      "Iteration 846, loss = 1.07657006\n",
      "Iteration 847, loss = 1.07640695\n",
      "Iteration 848, loss = 1.07624402\n",
      "Iteration 849, loss = 1.07608129\n",
      "Iteration 850, loss = 1.07591874\n",
      "Iteration 851, loss = 1.07575637\n",
      "Iteration 852, loss = 1.07559419\n",
      "Iteration 853, loss = 1.07543218\n",
      "Iteration 854, loss = 1.07527036\n",
      "Iteration 855, loss = 1.07510870\n",
      "Iteration 856, loss = 1.07494722\n",
      "Iteration 857, loss = 1.07478591\n",
      "Iteration 858, loss = 1.07462477\n",
      "Iteration 859, loss = 1.07446380\n",
      "Iteration 860, loss = 1.07430299\n",
      "Iteration 861, loss = 1.07414235\n",
      "Iteration 862, loss = 1.07398187\n",
      "Iteration 863, loss = 1.07382154\n",
      "Iteration 864, loss = 1.07366137\n",
      "Iteration 865, loss = 1.07350136\n",
      "Iteration 866, loss = 1.07334150\n",
      "Iteration 867, loss = 1.07318179\n",
      "Iteration 868, loss = 1.07302223\n",
      "Iteration 869, loss = 1.07286282\n",
      "Iteration 870, loss = 1.07270355\n",
      "Iteration 871, loss = 1.07254442\n",
      "Iteration 872, loss = 1.07238544\n",
      "Iteration 873, loss = 1.07222659\n",
      "Iteration 874, loss = 1.07206788\n",
      "Iteration 875, loss = 1.07190931\n",
      "Iteration 876, loss = 1.07175086\n",
      "Iteration 877, loss = 1.07159255\n",
      "Iteration 878, loss = 1.07143437\n",
      "Iteration 879, loss = 1.07127631\n",
      "Iteration 880, loss = 1.07111838\n",
      "Iteration 881, loss = 1.07096057\n",
      "Iteration 882, loss = 1.07080289\n",
      "Iteration 883, loss = 1.07064532\n",
      "Iteration 884, loss = 1.07048787\n",
      "Iteration 885, loss = 1.07033053\n",
      "Iteration 886, loss = 1.07017331\n",
      "Iteration 887, loss = 1.07001619\n",
      "Iteration 888, loss = 1.06985919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 889, loss = 1.06970229\n",
      "Iteration 890, loss = 1.06954550\n",
      "Iteration 891, loss = 1.06938881\n",
      "Iteration 892, loss = 1.06923222\n",
      "Iteration 893, loss = 1.06907573\n",
      "Iteration 894, loss = 1.06891934\n",
      "Iteration 895, loss = 1.06876304\n",
      "Iteration 896, loss = 1.06860684\n",
      "Iteration 897, loss = 1.06845072\n",
      "Iteration 898, loss = 1.06829470\n",
      "Iteration 899, loss = 1.06813876\n",
      "Iteration 900, loss = 1.06798291\n",
      "Iteration 901, loss = 1.06782715\n",
      "Iteration 902, loss = 1.06767146\n",
      "Iteration 903, loss = 1.06751585\n",
      "Iteration 904, loss = 1.06736032\n",
      "Iteration 905, loss = 1.06720487\n",
      "Iteration 906, loss = 1.06704949\n",
      "Iteration 907, loss = 1.06689418\n",
      "Iteration 908, loss = 1.06673894\n",
      "Iteration 909, loss = 1.06658377\n",
      "Iteration 910, loss = 1.06642867\n",
      "Iteration 911, loss = 1.06627363\n",
      "Iteration 912, loss = 1.06611865\n",
      "Iteration 913, loss = 1.06596373\n",
      "Iteration 914, loss = 1.06580888\n",
      "Iteration 915, loss = 1.06565407\n",
      "Iteration 916, loss = 1.06549932\n",
      "Iteration 917, loss = 1.06534463\n",
      "Iteration 918, loss = 1.06518998\n",
      "Iteration 919, loss = 1.06503539\n",
      "Iteration 920, loss = 1.06488084\n",
      "Iteration 921, loss = 1.06472634\n",
      "Iteration 922, loss = 1.06457188\n",
      "Iteration 923, loss = 1.06441746\n",
      "Iteration 924, loss = 1.06426308\n",
      "Iteration 925, loss = 1.06410874\n",
      "Iteration 926, loss = 1.06395443\n",
      "Iteration 927, loss = 1.06380016\n",
      "Iteration 928, loss = 1.06364592\n",
      "Iteration 929, loss = 1.06349171\n",
      "Iteration 930, loss = 1.06333753\n",
      "Iteration 931, loss = 1.06318337\n",
      "Iteration 932, loss = 1.06302924\n",
      "Iteration 933, loss = 1.06287514\n",
      "Iteration 934, loss = 1.06272105\n",
      "Iteration 935, loss = 1.06256699\n",
      "Iteration 936, loss = 1.06241294\n",
      "Iteration 937, loss = 1.06225891\n",
      "Iteration 938, loss = 1.06210489\n",
      "Iteration 939, loss = 1.06195088\n",
      "Iteration 940, loss = 1.06179689\n",
      "Iteration 941, loss = 1.06164290\n",
      "Iteration 942, loss = 1.06148892\n",
      "Iteration 943, loss = 1.06133495\n",
      "Iteration 944, loss = 1.06118097\n",
      "Iteration 945, loss = 1.06102700\n",
      "Iteration 946, loss = 1.06087304\n",
      "Iteration 947, loss = 1.06071906\n",
      "Iteration 948, loss = 1.06056509\n",
      "Iteration 949, loss = 1.06041111\n",
      "Iteration 950, loss = 1.06025712\n",
      "Iteration 951, loss = 1.06010313\n",
      "Iteration 952, loss = 1.05994912\n",
      "Iteration 953, loss = 1.05979510\n",
      "Iteration 954, loss = 1.05964107\n",
      "Iteration 955, loss = 1.05948703\n",
      "Iteration 956, loss = 1.05933296\n",
      "Iteration 957, loss = 1.05917888\n",
      "Iteration 958, loss = 1.05902478\n",
      "Iteration 959, loss = 1.05887065\n",
      "Iteration 960, loss = 1.05871650\n",
      "Iteration 961, loss = 1.05856233\n",
      "Iteration 962, loss = 1.05840813\n",
      "Iteration 963, loss = 1.05825390\n",
      "Iteration 964, loss = 1.05809964\n",
      "Iteration 965, loss = 1.05794536\n",
      "Iteration 966, loss = 1.05779103\n",
      "Iteration 967, loss = 1.05763667\n",
      "Iteration 968, loss = 1.05748228\n",
      "Iteration 969, loss = 1.05732785\n",
      "Iteration 970, loss = 1.05717338\n",
      "Iteration 971, loss = 1.05701887\n",
      "Iteration 972, loss = 1.05686431\n",
      "Iteration 973, loss = 1.05670971\n",
      "Iteration 974, loss = 1.05655507\n",
      "Iteration 975, loss = 1.05640038\n",
      "Iteration 976, loss = 1.05624564\n",
      "Iteration 977, loss = 1.05609085\n",
      "Iteration 978, loss = 1.05593601\n",
      "Iteration 979, loss = 1.05578112\n",
      "Iteration 980, loss = 1.05562617\n",
      "Iteration 981, loss = 1.05547117\n",
      "Iteration 982, loss = 1.05531611\n",
      "Iteration 983, loss = 1.05516100\n",
      "Iteration 984, loss = 1.05500582\n",
      "Iteration 985, loss = 1.05485058\n",
      "Iteration 986, loss = 1.05469528\n",
      "Iteration 987, loss = 1.05453991\n",
      "Iteration 988, loss = 1.05438448\n",
      "Iteration 989, loss = 1.05422899\n",
      "Iteration 990, loss = 1.05407342\n",
      "Iteration 991, loss = 1.05391779\n",
      "Iteration 992, loss = 1.05376208\n",
      "Iteration 993, loss = 1.05360631\n",
      "Iteration 994, loss = 1.05345046\n",
      "Iteration 995, loss = 1.05329453\n",
      "Iteration 996, loss = 1.05313853\n",
      "Iteration 997, loss = 1.05298246\n",
      "Iteration 998, loss = 1.05282630\n",
      "Iteration 999, loss = 1.05267007\n",
      "Iteration 1000, loss = 1.05251375\n",
      "Iteration 1001, loss = 1.05235736\n",
      "Iteration 1002, loss = 1.05220088\n",
      "Iteration 1003, loss = 1.05204432\n",
      "Iteration 1004, loss = 1.05188767\n",
      "Iteration 1005, loss = 1.05173093\n",
      "Iteration 1006, loss = 1.05157411\n",
      "Iteration 1007, loss = 1.05141720\n",
      "Iteration 1008, loss = 1.05126020\n",
      "Iteration 1009, loss = 1.05110310\n",
      "Iteration 1010, loss = 1.05094592\n",
      "Iteration 1011, loss = 1.05078864\n",
      "Iteration 1012, loss = 1.05063127\n",
      "Iteration 1013, loss = 1.05047380\n",
      "Iteration 1014, loss = 1.05031624\n",
      "Iteration 1015, loss = 1.05015858\n",
      "Iteration 1016, loss = 1.05000082\n",
      "Iteration 1017, loss = 1.04984296\n",
      "Iteration 1018, loss = 1.04968501\n",
      "Iteration 1019, loss = 1.04952695\n",
      "Iteration 1020, loss = 1.04936879\n",
      "Iteration 1021, loss = 1.04921052\n",
      "Iteration 1022, loss = 1.04905215\n",
      "Iteration 1023, loss = 1.04889368\n",
      "Iteration 1024, loss = 1.04873510\n",
      "Iteration 1025, loss = 1.04857641\n",
      "Iteration 1026, loss = 1.04841761\n",
      "Iteration 1027, loss = 1.04825871\n",
      "Iteration 1028, loss = 1.04809970\n",
      "Iteration 1029, loss = 1.04794057\n",
      "Iteration 1030, loss = 1.04778134\n",
      "Iteration 1031, loss = 1.04762199\n",
      "Iteration 1032, loss = 1.04746253\n",
      "Iteration 1033, loss = 1.04730296\n",
      "Iteration 1034, loss = 1.04714327\n",
      "Iteration 1035, loss = 1.04698346\n",
      "Iteration 1036, loss = 1.04682354\n",
      "Iteration 1037, loss = 1.04666350\n",
      "Iteration 1038, loss = 1.04650335\n",
      "Iteration 1039, loss = 1.04634308\n",
      "Iteration 1040, loss = 1.04618268\n",
      "Iteration 1041, loss = 1.04602217\n",
      "Iteration 1042, loss = 1.04586154\n",
      "Iteration 1043, loss = 1.04570078\n",
      "Iteration 1044, loss = 1.04553990\n",
      "Iteration 1045, loss = 1.04537890\n",
      "Iteration 1046, loss = 1.04521778\n",
      "Iteration 1047, loss = 1.04505653\n",
      "Iteration 1048, loss = 1.04489516\n",
      "Iteration 1049, loss = 1.04473366\n",
      "Iteration 1050, loss = 1.04457204\n",
      "Iteration 1051, loss = 1.04441029\n",
      "Iteration 1052, loss = 1.04424841\n",
      "Iteration 1053, loss = 1.04408641\n",
      "Iteration 1054, loss = 1.04392427\n",
      "Iteration 1055, loss = 1.04376201\n",
      "Iteration 1056, loss = 1.04359962\n",
      "Iteration 1057, loss = 1.04343709\n",
      "Iteration 1058, loss = 1.04327444\n",
      "Iteration 1059, loss = 1.04311165\n",
      "Iteration 1060, loss = 1.04294873\n",
      "Iteration 1061, loss = 1.04278568\n",
      "Iteration 1062, loss = 1.04262250\n",
      "Iteration 1063, loss = 1.04245918\n",
      "Iteration 1064, loss = 1.04229573\n",
      "Iteration 1065, loss = 1.04213214\n",
      "Iteration 1066, loss = 1.04196842\n",
      "Iteration 1067, loss = 1.04180456\n",
      "Iteration 1068, loss = 1.04164057\n",
      "Iteration 1069, loss = 1.04147643\n",
      "Iteration 1070, loss = 1.04131217\n",
      "Iteration 1071, loss = 1.04114776\n",
      "Iteration 1072, loss = 1.04098322\n",
      "Iteration 1073, loss = 1.04081853\n",
      "Iteration 1074, loss = 1.04065371\n",
      "Iteration 1075, loss = 1.04048875\n",
      "Iteration 1076, loss = 1.04032364\n",
      "Iteration 1077, loss = 1.04015840\n",
      "Iteration 1078, loss = 1.03999302\n",
      "Iteration 1079, loss = 1.03982749\n",
      "Iteration 1080, loss = 1.03966182\n",
      "Iteration 1081, loss = 1.03949601\n",
      "Iteration 1082, loss = 1.03933006\n",
      "Iteration 1083, loss = 1.03916396\n",
      "Iteration 1084, loss = 1.03899772\n",
      "Iteration 1085, loss = 1.03883133\n",
      "Iteration 1086, loss = 1.03866480\n",
      "Iteration 1087, loss = 1.03849812\n",
      "Iteration 1088, loss = 1.03833130\n",
      "Iteration 1089, loss = 1.03816433\n",
      "Iteration 1090, loss = 1.03799722\n",
      "Iteration 1091, loss = 1.03782996\n",
      "Iteration 1092, loss = 1.03766255\n",
      "Iteration 1093, loss = 1.03749499\n",
      "Iteration 1094, loss = 1.03732729\n",
      "Iteration 1095, loss = 1.03715943\n",
      "Iteration 1096, loss = 1.03699143\n",
      "Iteration 1097, loss = 1.03682327\n",
      "Iteration 1098, loss = 1.03665497\n",
      "Iteration 1099, loss = 1.03648651\n",
      "Iteration 1100, loss = 1.03631791\n",
      "Iteration 1101, loss = 1.03614915\n",
      "Iteration 1102, loss = 1.03598024\n",
      "Iteration 1103, loss = 1.03581118\n",
      "Iteration 1104, loss = 1.03564196\n",
      "Iteration 1105, loss = 1.03547259\n",
      "Iteration 1106, loss = 1.03530307\n",
      "Iteration 1107, loss = 1.03513339\n",
      "Iteration 1108, loss = 1.03496356\n",
      "Iteration 1109, loss = 1.03479357\n",
      "Iteration 1110, loss = 1.03462343\n",
      "Iteration 1111, loss = 1.03445313\n",
      "Iteration 1112, loss = 1.03428267\n",
      "Iteration 1113, loss = 1.03411205\n",
      "Iteration 1114, loss = 1.03394128\n",
      "Iteration 1115, loss = 1.03377035\n",
      "Iteration 1116, loss = 1.03359926\n",
      "Iteration 1117, loss = 1.03342801\n",
      "Iteration 1118, loss = 1.03325659\n",
      "Iteration 1119, loss = 1.03308502\n",
      "Iteration 1120, loss = 1.03291329\n",
      "Iteration 1121, loss = 1.03274139\n",
      "Iteration 1122, loss = 1.03256933\n",
      "Iteration 1123, loss = 1.03239711\n",
      "Iteration 1124, loss = 1.03222473\n",
      "Iteration 1125, loss = 1.03205218\n",
      "Iteration 1126, loss = 1.03187946\n",
      "Iteration 1127, loss = 1.03170658\n",
      "Iteration 1128, loss = 1.03153354\n",
      "Iteration 1129, loss = 1.03136032\n",
      "Iteration 1130, loss = 1.03118694\n",
      "Iteration 1131, loss = 1.03101339\n",
      "Iteration 1132, loss = 1.03083968\n",
      "Iteration 1133, loss = 1.03066579\n",
      "Iteration 1134, loss = 1.03049173\n",
      "Iteration 1135, loss = 1.03031750\n",
      "Iteration 1136, loss = 1.03014310\n",
      "Iteration 1137, loss = 1.02996853\n",
      "Iteration 1138, loss = 1.02979378\n",
      "Iteration 1139, loss = 1.02961886\n",
      "Iteration 1140, loss = 1.02944377\n",
      "Iteration 1141, loss = 1.02926850\n",
      "Iteration 1142, loss = 1.02909305\n",
      "Iteration 1143, loss = 1.02891743\n",
      "Iteration 1144, loss = 1.02874163\n",
      "Iteration 1145, loss = 1.02856565\n",
      "Iteration 1146, loss = 1.02838949\n",
      "Iteration 1147, loss = 1.02821315\n",
      "Iteration 1148, loss = 1.02803663\n",
      "Iteration 1149, loss = 1.02785993\n",
      "Iteration 1150, loss = 1.02768304\n",
      "Iteration 1151, loss = 1.02750597\n",
      "Iteration 1152, loss = 1.02732872\n",
      "Iteration 1153, loss = 1.02715128\n",
      "Iteration 1154, loss = 1.02697365\n",
      "Iteration 1155, loss = 1.02679584\n",
      "Iteration 1156, loss = 1.02661783\n",
      "Iteration 1157, loss = 1.02643964\n",
      "Iteration 1158, loss = 1.02626126\n",
      "Iteration 1159, loss = 1.02608268\n",
      "Iteration 1160, loss = 1.02590392\n",
      "Iteration 1161, loss = 1.02572496\n",
      "Iteration 1162, loss = 1.02554580\n",
      "Iteration 1163, loss = 1.02536645\n",
      "Iteration 1164, loss = 1.02518691\n",
      "Iteration 1165, loss = 1.02500716\n",
      "Iteration 1166, loss = 1.02482722\n",
      "Iteration 1167, loss = 1.02464708\n",
      "Iteration 1168, loss = 1.02446674\n",
      "Iteration 1169, loss = 1.02428619\n",
      "Iteration 1170, loss = 1.02410544\n",
      "Iteration 1171, loss = 1.02392449\n",
      "Iteration 1172, loss = 1.02374333\n",
      "Iteration 1173, loss = 1.02356196\n",
      "Iteration 1174, loss = 1.02338039\n",
      "Iteration 1175, loss = 1.02319861\n",
      "Iteration 1176, loss = 1.02301661\n",
      "Iteration 1177, loss = 1.02283441\n",
      "Iteration 1178, loss = 1.02265199\n",
      "Iteration 1179, loss = 1.02246936\n",
      "Iteration 1180, loss = 1.02228651\n",
      "Iteration 1181, loss = 1.02210345\n",
      "Iteration 1182, loss = 1.02192017\n",
      "Iteration 1183, loss = 1.02173667\n",
      "Iteration 1184, loss = 1.02155295\n",
      "Iteration 1185, loss = 1.02136900\n",
      "Iteration 1186, loss = 1.02118484\n",
      "Iteration 1187, loss = 1.02100044\n",
      "Iteration 1188, loss = 1.02081583\n",
      "Iteration 1189, loss = 1.02063098\n",
      "Iteration 1190, loss = 1.02044591\n",
      "Iteration 1191, loss = 1.02026060\n",
      "Iteration 1192, loss = 1.02007507\n",
      "Iteration 1193, loss = 1.01988930\n",
      "Iteration 1194, loss = 1.01970330\n",
      "Iteration 1195, loss = 1.01951706\n",
      "Iteration 1196, loss = 1.01933058\n",
      "Iteration 1197, loss = 1.01914387\n",
      "Iteration 1198, loss = 1.01895691\n",
      "Iteration 1199, loss = 1.01876971\n",
      "Iteration 1200, loss = 1.01858227\n",
      "Iteration 1201, loss = 1.01839458\n",
      "Iteration 1202, loss = 1.01820665\n",
      "Iteration 1203, loss = 1.01801847\n",
      "Iteration 1204, loss = 1.01783003\n",
      "Iteration 1205, loss = 1.01764135\n",
      "Iteration 1206, loss = 1.01745241\n",
      "Iteration 1207, loss = 1.01726322\n",
      "Iteration 1208, loss = 1.01707378\n",
      "Iteration 1209, loss = 1.01688407\n",
      "Iteration 1210, loss = 1.01669411\n",
      "Iteration 1211, loss = 1.01650388\n",
      "Iteration 1212, loss = 1.01631339\n",
      "Iteration 1213, loss = 1.01612264\n",
      "Iteration 1214, loss = 1.01593162\n",
      "Iteration 1215, loss = 1.01574034\n",
      "Iteration 1216, loss = 1.01554878\n",
      "Iteration 1217, loss = 1.01535695\n",
      "Iteration 1218, loss = 1.01516485\n",
      "Iteration 1219, loss = 1.01497248\n",
      "Iteration 1220, loss = 1.01477982\n",
      "Iteration 1221, loss = 1.01458689\n",
      "Iteration 1222, loss = 1.01439368\n",
      "Iteration 1223, loss = 1.01420019\n",
      "Iteration 1224, loss = 1.01400642\n",
      "Iteration 1225, loss = 1.01381236\n",
      "Iteration 1226, loss = 1.01361801\n",
      "Iteration 1227, loss = 1.01342337\n",
      "Iteration 1228, loss = 1.01322844\n",
      "Iteration 1229, loss = 1.01303322\n",
      "Iteration 1230, loss = 1.01283771\n",
      "Iteration 1231, loss = 1.01264189\n",
      "Iteration 1232, loss = 1.01244578\n",
      "Iteration 1233, loss = 1.01224937\n",
      "Iteration 1234, loss = 1.01205266\n",
      "Iteration 1235, loss = 1.01185564\n",
      "Iteration 1236, loss = 1.01165832\n",
      "Iteration 1237, loss = 1.01146069\n",
      "Iteration 1238, loss = 1.01126275\n",
      "Iteration 1239, loss = 1.01106450\n",
      "Iteration 1240, loss = 1.01086594\n",
      "Iteration 1241, loss = 1.01066706\n",
      "Iteration 1242, loss = 1.01046786\n",
      "Iteration 1243, loss = 1.01026834\n",
      "Iteration 1244, loss = 1.01006850\n",
      "Iteration 1245, loss = 1.00986834\n",
      "Iteration 1246, loss = 1.00966785\n",
      "Iteration 1247, loss = 1.00946704\n",
      "Iteration 1248, loss = 1.00926589\n",
      "Iteration 1249, loss = 1.00906442\n",
      "Iteration 1250, loss = 1.00886261\n",
      "Iteration 1251, loss = 1.00866046\n",
      "Iteration 1252, loss = 1.00845798\n",
      "Iteration 1253, loss = 1.00825516\n",
      "Iteration 1254, loss = 1.00805199\n",
      "Iteration 1255, loss = 1.00784848\n",
      "Iteration 1256, loss = 1.00764463\n",
      "Iteration 1257, loss = 1.00744043\n",
      "Iteration 1258, loss = 1.00723588\n",
      "Iteration 1259, loss = 1.00703097\n",
      "Iteration 1260, loss = 1.00682571\n",
      "Iteration 1261, loss = 1.00662010\n",
      "Iteration 1262, loss = 1.00641413\n",
      "Iteration 1263, loss = 1.00620779\n",
      "Iteration 1264, loss = 1.00600110\n",
      "Iteration 1265, loss = 1.00579404\n",
      "Iteration 1266, loss = 1.00558661\n",
      "Iteration 1267, loss = 1.00537881\n",
      "Iteration 1268, loss = 1.00517064\n",
      "Iteration 1269, loss = 1.00496210\n",
      "Iteration 1270, loss = 1.00475318\n",
      "Iteration 1271, loss = 1.00454388\n",
      "Iteration 1272, loss = 1.00433421\n",
      "Iteration 1273, loss = 1.00412415\n",
      "Iteration 1274, loss = 1.00391370\n",
      "Iteration 1275, loss = 1.00370287\n",
      "Iteration 1276, loss = 1.00349165\n",
      "Iteration 1277, loss = 1.00328004\n",
      "Iteration 1278, loss = 1.00306803\n",
      "Iteration 1279, loss = 1.00285563\n",
      "Iteration 1280, loss = 1.00264283\n",
      "Iteration 1281, loss = 1.00242963\n",
      "Iteration 1282, loss = 1.00221602\n",
      "Iteration 1283, loss = 1.00200201\n",
      "Iteration 1284, loss = 1.00178760\n",
      "Iteration 1285, loss = 1.00157277\n",
      "Iteration 1286, loss = 1.00135753\n",
      "Iteration 1287, loss = 1.00114187\n",
      "Iteration 1288, loss = 1.00092580\n",
      "Iteration 1289, loss = 1.00070931\n",
      "Iteration 1290, loss = 1.00049240\n",
      "Iteration 1291, loss = 1.00027506\n",
      "Iteration 1292, loss = 1.00005730\n",
      "Iteration 1293, loss = 0.99983911\n",
      "Iteration 1294, loss = 0.99962048\n",
      "Iteration 1295, loss = 0.99940143\n",
      "Iteration 1296, loss = 0.99918193\n",
      "Iteration 1297, loss = 0.99896200\n",
      "Iteration 1298, loss = 0.99874162\n",
      "Iteration 1299, loss = 0.99852081\n",
      "Iteration 1300, loss = 0.99829954\n",
      "Iteration 1301, loss = 0.99807783\n",
      "Iteration 1302, loss = 0.99785566\n",
      "Iteration 1303, loss = 0.99763305\n",
      "Iteration 1304, loss = 0.99740997\n",
      "Iteration 1305, loss = 0.99718644\n",
      "Iteration 1306, loss = 0.99696244\n",
      "Iteration 1307, loss = 0.99673798\n",
      "Iteration 1308, loss = 0.99651305\n",
      "Iteration 1309, loss = 0.99628766\n",
      "Iteration 1310, loss = 0.99606179\n",
      "Iteration 1311, loss = 0.99583545\n",
      "Iteration 1312, loss = 0.99560863\n",
      "Iteration 1313, loss = 0.99538133\n",
      "Iteration 1314, loss = 0.99515355\n",
      "Iteration 1315, loss = 0.99492528\n",
      "Iteration 1316, loss = 0.99469652\n",
      "Iteration 1317, loss = 0.99446728\n",
      "Iteration 1318, loss = 0.99423754\n",
      "Iteration 1319, loss = 0.99400730\n",
      "Iteration 1320, loss = 0.99377656\n",
      "Iteration 1321, loss = 0.99354533\n",
      "Iteration 1322, loss = 0.99331358\n",
      "Iteration 1323, loss = 0.99308133\n",
      "Iteration 1324, loss = 0.99284857\n",
      "Iteration 1325, loss = 0.99261530\n",
      "Iteration 1326, loss = 0.99238151\n",
      "Iteration 1327, loss = 0.99214720\n",
      "Iteration 1328, loss = 0.99191237\n",
      "Iteration 1329, loss = 0.99167702\n",
      "Iteration 1330, loss = 0.99144114\n",
      "Iteration 1331, loss = 0.99120472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1332, loss = 0.99096778\n",
      "Iteration 1333, loss = 0.99073029\n",
      "Iteration 1334, loss = 0.99049227\n",
      "Iteration 1335, loss = 0.99025370\n",
      "Iteration 1336, loss = 0.99001459\n",
      "Iteration 1337, loss = 0.98977493\n",
      "Iteration 1338, loss = 0.98953471\n",
      "Iteration 1339, loss = 0.98929395\n",
      "Iteration 1340, loss = 0.98905262\n",
      "Iteration 1341, loss = 0.98881073\n",
      "Iteration 1342, loss = 0.98856828\n",
      "Iteration 1343, loss = 0.98832526\n",
      "Iteration 1344, loss = 0.98808166\n",
      "Iteration 1345, loss = 0.98783750\n",
      "Iteration 1346, loss = 0.98759275\n",
      "Iteration 1347, loss = 0.98734743\n",
      "Iteration 1348, loss = 0.98710152\n",
      "Iteration 1349, loss = 0.98685502\n",
      "Iteration 1350, loss = 0.98660793\n",
      "Iteration 1351, loss = 0.98636025\n",
      "Iteration 1352, loss = 0.98611196\n",
      "Iteration 1353, loss = 0.98586308\n",
      "Iteration 1354, loss = 0.98561359\n",
      "Iteration 1355, loss = 0.98536349\n",
      "Iteration 1356, loss = 0.98511279\n",
      "Iteration 1357, loss = 0.98486146\n",
      "Iteration 1358, loss = 0.98460952\n",
      "Iteration 1359, loss = 0.98435695\n",
      "Iteration 1360, loss = 0.98410375\n",
      "Iteration 1361, loss = 0.98384993\n",
      "Iteration 1362, loss = 0.98359547\n",
      "Iteration 1363, loss = 0.98334037\n",
      "Iteration 1364, loss = 0.98308463\n",
      "Iteration 1365, loss = 0.98282825\n",
      "Iteration 1366, loss = 0.98257122\n",
      "Iteration 1367, loss = 0.98231353\n",
      "Iteration 1368, loss = 0.98205518\n",
      "Iteration 1369, loss = 0.98179618\n",
      "Iteration 1370, loss = 0.98153651\n",
      "Iteration 1371, loss = 0.98127617\n",
      "Iteration 1372, loss = 0.98101515\n",
      "Iteration 1373, loss = 0.98075346\n",
      "Iteration 1374, loss = 0.98049109\n",
      "Iteration 1375, loss = 0.98022803\n",
      "Iteration 1376, loss = 0.97996428\n",
      "Iteration 1377, loss = 0.97969983\n",
      "Iteration 1378, loss = 0.97943469\n",
      "Iteration 1379, loss = 0.97916884\n",
      "Iteration 1380, loss = 0.97890228\n",
      "Iteration 1381, loss = 0.97863502\n",
      "Iteration 1382, loss = 0.97836703\n",
      "Iteration 1383, loss = 0.97809833\n",
      "Iteration 1384, loss = 0.97782890\n",
      "Iteration 1385, loss = 0.97755874\n",
      "Iteration 1386, loss = 0.97728784\n",
      "Iteration 1387, loss = 0.97701620\n",
      "Iteration 1388, loss = 0.97674382\n",
      "Iteration 1389, loss = 0.97647069\n",
      "Iteration 1390, loss = 0.97619681\n",
      "Iteration 1391, loss = 0.97592216\n",
      "Iteration 1392, loss = 0.97564675\n",
      "Iteration 1393, loss = 0.97537057\n",
      "Iteration 1394, loss = 0.97509362\n",
      "Iteration 1395, loss = 0.97481589\n",
      "Iteration 1396, loss = 0.97453737\n",
      "Iteration 1397, loss = 0.97425806\n",
      "Iteration 1398, loss = 0.97397796\n",
      "Iteration 1399, loss = 0.97369705\n",
      "Iteration 1400, loss = 0.97341534\n",
      "Iteration 1401, loss = 0.97313282\n",
      "Iteration 1402, loss = 0.97284948\n",
      "Iteration 1403, loss = 0.97256532\n",
      "Iteration 1404, loss = 0.97228033\n",
      "Iteration 1405, loss = 0.97199450\n",
      "Iteration 1406, loss = 0.97170784\n",
      "Iteration 1407, loss = 0.97142033\n",
      "Iteration 1408, loss = 0.97113196\n",
      "Iteration 1409, loss = 0.97084274\n",
      "Iteration 1410, loss = 0.97055266\n",
      "Iteration 1411, loss = 0.97026170\n",
      "Iteration 1412, loss = 0.96996987\n",
      "Iteration 1413, loss = 0.96967715\n",
      "Iteration 1414, loss = 0.96938355\n",
      "Iteration 1415, loss = 0.96908905\n",
      "Iteration 1416, loss = 0.96879365\n",
      "Iteration 1417, loss = 0.96849733\n",
      "Iteration 1418, loss = 0.96820011\n",
      "Iteration 1419, loss = 0.96790196\n",
      "Iteration 1420, loss = 0.96760288\n",
      "Iteration 1421, loss = 0.96730287\n",
      "Iteration 1422, loss = 0.96700192\n",
      "Iteration 1423, loss = 0.96670001\n",
      "Iteration 1424, loss = 0.96639715\n",
      "Iteration 1425, loss = 0.96609332\n",
      "Iteration 1426, loss = 0.96578852\n",
      "Iteration 1427, loss = 0.96548275\n",
      "Iteration 1428, loss = 0.96517598\n",
      "Iteration 1429, loss = 0.96486822\n",
      "Iteration 1430, loss = 0.96455946\n",
      "Iteration 1431, loss = 0.96424969\n",
      "Iteration 1432, loss = 0.96393891\n",
      "Iteration 1433, loss = 0.96362710\n",
      "Iteration 1434, loss = 0.96331425\n",
      "Iteration 1435, loss = 0.96300036\n",
      "Iteration 1436, loss = 0.96268542\n",
      "Iteration 1437, loss = 0.96236943\n",
      "Iteration 1438, loss = 0.96205237\n",
      "Iteration 1439, loss = 0.96173423\n",
      "Iteration 1440, loss = 0.96141500\n",
      "Iteration 1441, loss = 0.96109469\n",
      "Iteration 1442, loss = 0.96077327\n",
      "Iteration 1443, loss = 0.96045074\n",
      "Iteration 1444, loss = 0.96012709\n",
      "Iteration 1445, loss = 0.95980232\n",
      "Iteration 1446, loss = 0.95947640\n",
      "Iteration 1447, loss = 0.95914934\n",
      "Iteration 1448, loss = 0.95882111\n",
      "Iteration 1449, loss = 0.95849172\n",
      "Iteration 1450, loss = 0.95816116\n",
      "Iteration 1451, loss = 0.95782940\n",
      "Iteration 1452, loss = 0.95749645\n",
      "Iteration 1453, loss = 0.95716229\n",
      "Iteration 1454, loss = 0.95682691\n",
      "Iteration 1455, loss = 0.95649031\n",
      "Iteration 1456, loss = 0.95615246\n",
      "Iteration 1457, loss = 0.95581337\n",
      "Iteration 1458, loss = 0.95547301\n",
      "Iteration 1459, loss = 0.95513138\n",
      "Iteration 1460, loss = 0.95478847\n",
      "Iteration 1461, loss = 0.95444427\n",
      "Iteration 1462, loss = 0.95409876\n",
      "Iteration 1463, loss = 0.95375193\n",
      "Iteration 1464, loss = 0.95340378\n",
      "Iteration 1465, loss = 0.95305428\n",
      "Iteration 1466, loss = 0.95270343\n",
      "Iteration 1467, loss = 0.95235122\n",
      "Iteration 1468, loss = 0.95199762\n",
      "Iteration 1469, loss = 0.95164264\n",
      "Iteration 1470, loss = 0.95128626\n",
      "Iteration 1471, loss = 0.95092846\n",
      "Iteration 1472, loss = 0.95056923\n",
      "Iteration 1473, loss = 0.95020856\n",
      "Iteration 1474, loss = 0.94984644\n",
      "Iteration 1475, loss = 0.94948285\n",
      "Iteration 1476, loss = 0.94911778\n",
      "Iteration 1477, loss = 0.94875121\n",
      "Iteration 1478, loss = 0.94838314\n",
      "Iteration 1479, loss = 0.94801354\n",
      "Iteration 1480, loss = 0.94764240\n",
      "Iteration 1481, loss = 0.94726971\n",
      "Iteration 1482, loss = 0.94689546\n",
      "Iteration 1483, loss = 0.94651962\n",
      "Iteration 1484, loss = 0.94614219\n",
      "Iteration 1485, loss = 0.94576315\n",
      "Iteration 1486, loss = 0.94538248\n",
      "Iteration 1487, loss = 0.94500017\n",
      "Iteration 1488, loss = 0.94461620\n",
      "Iteration 1489, loss = 0.94423056\n",
      "Iteration 1490, loss = 0.94384323\n",
      "Iteration 1491, loss = 0.94345420\n",
      "Iteration 1492, loss = 0.94306344\n",
      "Iteration 1493, loss = 0.94267094\n",
      "Iteration 1494, loss = 0.94227669\n",
      "Iteration 1495, loss = 0.94188067\n",
      "Iteration 1496, loss = 0.94148286\n",
      "Iteration 1497, loss = 0.94108324\n",
      "Iteration 1498, loss = 0.94068180\n",
      "Iteration 1499, loss = 0.94027852\n",
      "Iteration 1500, loss = 0.93987338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leninml/anaconda3/envs/MachineLearning/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=1500, momentum=0.95,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='sgd', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_iris.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Evaluando el desempeño de entrenamiento de la Red Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8583333333333333"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_iris.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Evaluando el desempeño de la Red Iris en el dataset de Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_iris.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Dibujando la función de pérdida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl0XOWZ5/Hvo33fJUuWLMsG26xmE7vDkk4TYEjT6aG7YWggCYyHTqeH9DDpA+mZdE96O+l0cpJMFuIAA+kmkIQtNIGAk5AQlhhsxxs2xsY2WLJsSZatzVos+Zk/6kqUbckqWSXdctXvc04dVb33LdWja9fv3nrve+uauyMiIqkjLewCRERkZin4RURSjIJfRCTFKPhFRFKMgl9EJMUo+EVEUoyCX0QkxSj4RURSjIJfRCTFZIRdwFgqKiq8oaEh7DJERE4Yq1atanf3ylj6JmTwNzQ0sHLlyrDLEBE5YZjZe7H21VCPiEiKmXCP38zmAN8HZgEOLHP3rx/R53PAzVG/81Sg0t07zGwH0A0MA0Pu3hi/8kVEZLJiGeoZAu5299VmVgisMrPl7r5xpIO7fxn4MoCZfQz4K3fviPodV7p7ezwLFxGR4zPhUI+7t7j76uB+N7AJqD3GU24CHo1PeSIiEm+TGuM3swbgHGDFOMvzgKuBJ6KaHXjRzFaZ2dLjK1NEROIl5lk9ZlZAJNA/6+5d43T7GPDqEcM8S9y92cyqgOVm9ra7vzzG718KLAWor6+P+Q8QEZHJiWmP38wyiYT+I+7+5DG63sgRwzzu3hz8bAWeAi4Y64nuvszdG929sbIypqmoIiJyHCYMfjMz4AFgk7t/9Rj9ioHLgZ9EteUHB4Qxs3zgKmDDVIseS//BYZa9/C4rtu2djl8vIpI0YhnquRS4BVhvZmuCts8D9QDufl/Q9nHgRXfvjXruLOCpyLaDDOAH7v6zeBR+JDN44JXtzK8o4NGl5dPxEiIiSWHC4Hf3VwCLod9DwENHtG0DzjrO2iYlOyOdP7twLl9Z/g6t3f1UFebMxMuKiJxwkurM3StPqQLg9Xc13CMiMp6kCv5TqgvJzkhjfVNn2KWIiCSspAr+jPQ0Tqkp4q1d4802FRGRpAp+gNNnF/HWrk7cPexSREQSUtIF/4KqArr6h9jbOxh2KSIiCSnpgr+hPB+AHe29E/QUEUlNyRf8FZHg367gFxEZU9IFf11pLulpxo69Cn4RkbEkXfBnpqcxpzSXHe0Hwi5FRCQhJV3wA8wtz+e9Du3xi4iMJSmDv7Y0l137+8MuQ0QkISVn8Jfk0tE7SN/gcNiliIgknKQNfoDm/X0hVyIikniSMvhnB8G/S8EvInKUJA3+yFcyK/hFRI6WlMFfXZRDmmmoR0RkLEkZ/BnpaVQX5Sj4RUTGkJTBD5Fxfg31iIgcLWmDX3P5RUTGNmHwm9kcM3vJzDaa2VtmdtcYfa4ws04zWxPcvhC17Goz22xmW83snnj/AeOZXZJLS2cfhw7pe/lFRKJNeLF1YAi4291Xm1khsMrMlrv7xiP6/cbdr4tuMLN04FvA7wNNwJtm9swYz4272SW5HBx22nsGqCrShddFREZMuMfv7i3uvjq43w1sAmpj/P0XAFvdfZu7DwKPAdcfb7GTMbs4EvY6wCsicrhJjfGbWQNwDrBijMUXm9laM3vezE4P2mqBnVF9moh9ozElNcWRk7haOjXOLyISLZahHgDMrAB4Avisux95NfPVwFx37zGza4GngQWTKcTMlgJLAerr6yfz1DHV6uxdEZExxbTHb2aZREL/EXd/8sjl7t7l7j3B/eeATDOrAJqBOVFd64K2o7j7MndvdPfGysrKSf4ZRyvKzSAvK10ze0REjhDLrB4DHgA2uftXx+lTHfTDzC4Ifu9e4E1ggZnNM7Ms4EbgmXgVP0HdmssvIjKGWIZ6LgVuAdab2Zqg7fNAPYC73wfcAPy5mQ0BfcCN7u7AkJl9BngBSAcedPe34vw3jKumOIeWTgW/iEi0CYPf3V8BbII+3wS+Oc6y54Dnjqu6KaotyWVTS3cYLy0ikrCS9sxdiMzsae8ZYGBIF2QRERmR1ME/8vXMezoHQq5ERCRxJHnw60pcIiJHSong1wFeEZEPJHXw1xTrSlwiIkdK6uDPyUynLD+LXfraBhGRUUkd/BA5wKs9fhGRDyR98NcU59Kir20QERmV9MFfq69tEBE5TNIHf01xDt0DQ3T1Hwy7FBGRhJD0wT86pVPDPSIiQEoEfzClU3P5RUSAlAh+7fGLiERL+uCvKswhPc10gFdEJJD0wZ+eZlQX5WioR0QkkPTBD5GZPdrjFxGJSI3gL8mlRV/bICICpEjwzy7JoWV/P4cOediliIiELjWCvziXweFD7O0dDLsUEZHQTRj8ZjbHzF4ys41m9paZ3TVGn5vNbJ2ZrTez18zsrKhlO4L2NWa2Mt5/QCxGpnRqnF9EJIaLrQNDwN3uvtrMCoFVZrbc3TdG9dkOXO7u+8zsGmAZcGHU8ivdvT1+ZU/OyPfyt3T2cdackrDKEBFJCBMGv7u3AC3B/W4z2wTUAhuj+rwW9ZTfAnVxrnNKakcvwagDvCIikxrjN7MG4BxgxTG63Q48H/XYgRfNbJWZLZ1sgfFQkpdJTmYaLRrqERGJaagHADMrAJ4APuvuXeP0uZJI8C+Jal7i7s1mVgUsN7O33f3lMZ67FFgKUF9fP4k/IabamV2Sq5O4RESIcY/fzDKJhP4j7v7kOH0WA/cD17v73pF2d28OfrYCTwEXjPV8d1/m7o3u3lhZWTm5vyIGs4tz2aWhHhGRmGb1GPAAsMndvzpOn3rgSeAWd38nqj0/OCCMmeUDVwEb4lH4ZNWW5NKsoR4RkZiGei4FbgHWm9maoO3zQD2Au98HfAEoB74d2U4w5O6NwCzgqaAtA/iBu/8srn9BjOpKc2nrHqD/4DA5melhlCAikhBimdXzCmAT9LkDuGOM9m3AWUc/Y+bVlY3M7OnjpMqCkKsREQlPSpy5C1BXmgfAzo4DIVciIhKulAn+OUHwN+3TOL+IpLaUCf6qwmwy003BLyIpL2WCPy3NqC3JpWmfhnpEJLWlTPADzCnLY6f2+EUkxaVU8NeV5tKsPX4RSXEpFvx5tPcM0jc4HHYpIiKhSbHgj8zl1zi/iKSyFAt+TekUEUmp4J+jPX4RkdQK/srCbLIz0jSzR0RSWkoFv5lRW6q5/CKS2lIq+CEyzq8xfhFJZSkX/PVluby3V3v8IpK6Ui74G8rz6ew7yL7ewbBLEREJRcoF//zKfAC2tfeGXImISDhSLvgbyiPBv13BLyIpKuWCf05ZHulpxg4Fv4ikqJQL/sz0NOaU5mqPX0RS1oTBb2ZzzOwlM9toZm+Z2V1j9DEz+4aZbTWzdWZ2btSy28xsS3C7Ld5/wPGYV5GvMX4RSVkTXmwdGALudvfVZlYIrDKz5e6+MarPNcCC4HYh8B3gQjMrA/4WaAQ8eO4z7r4vrn/FJM2rKOC32zpwd8yOeR15EZGkM+Eev7u3uPvq4H43sAmoPaLb9cD3PeK3QImZ1QAfBZa7e0cQ9suBq+P6FxyHeRV59B0cZk/XQNiliIjMuEmN8ZtZA3AOsOKIRbXAzqjHTUHbeO1j/e6lZrbSzFa2tbVNpqxJm1dRAMC2tp5pfR0RkUQUc/CbWQHwBPBZd++KdyHuvszdG929sbKyMt6//jAnVUWmdG5V8ItICoop+M0sk0joP+LuT47RpRmYE/W4Lmgbrz1U1UU5FOVk8Pbu7rBLERGZcbHM6jHgAWCTu391nG7PALcGs3suAjrdvQV4AbjKzErNrBS4KmgLlZmxqLqQdxT8IpKCYpnVcylwC7DezNYEbZ8H6gHc/T7gOeBaYCtwAPhksKzDzP4eeDN43hfdvSN+5R+/RdWF/GTNLs3sEZGUM2Hwu/srwDGT0d0d+Itxlj0IPHhc1U2jRbMK6e4foqWzn9kluWGXIyIyY1LuzN0Ri6qLANis4R4RSTGpG/yzCgHYvEfBLyKpJWWDvzgvk+qiHO3xi0jKSdngBzi1ppCNu+J+SoKISEJL6eA/s66ELa3dHBgcCrsUEZEZk9LBv7i2mEOO9vpFJKWkdvDXFQOwtqkz5EpERGZOSgd/VVEO1UU5rG/aH3YpIiIzJqWDH+DMumLWNWuPX0RSR8oH/+LaYra19dLVfzDsUkREZkTKB//Z9SUArHlfwz0ikhpSPvjPrS8lPc14Y3tCfHeciMi0S/ngz8/O4PTZRbyxQ8EvIqkh5YMf4IKGMtbs3M/A0HDYpYiITDsFP3D+vDIGhw6xXvP5RSQFKPiB8xvKAFihcX4RSQEKfqAsP4tTqgt5dWt72KWIiEw7BX/g8oWVvLmjg94BfWGbiCS3WC62/qCZtZrZhnGWf87M1gS3DWY2bGZlwbIdZrY+WLYy3sXH0+ULKzk47Lz+7t6wSxERmVax7PE/BFw93kJ3/7K7n+3uZwP3Ar8+4oLqVwbLG6dW6vQ6r6GUvKx0fv1OW9iliIhMqwmD391fBmI96nkT8OiUKgpJdkY6l5xUzq/eaSVy7XgRkeQUtzF+M8sj8sngiahmB140s1VmtjRerzVdrjylip0dfbytyzGKSBKL58HdjwGvHjHMs8TdzwWuAf7CzC4b78lmttTMVprZyra2cIZbPnp6NWkGz61vCeX1RURmQjyD/0aOGOZx9+bgZyvwFHDBeE9292Xu3ujujZWVlXEsK3YVBdlcOK+cn65v0XCPiCStuAS/mRUDlwM/iWrLN7PCkfvAVcCYM4MSybWLa9jW1ss7e3rCLkVEZFrEMp3zUeB1YJGZNZnZ7WZ2p5ndGdXt48CL7t4b1TYLeMXM1gJvAD9195/Fs/jpcPXp1aSnGU+vaQ67FBGRaZExUQd3vymGPg8RmfYZ3bYNOOt4CwtLZWE2Vy6q5PFVTdz9+wvJSNc5biKSXJRqY/jT8+tp6x7gpc2a0y8iyUfBP4YrF1VSWZjND9/cGXYpIiJxp+AfQ0Z6GjecV8dLm1tp3t8XdjkiInGl4B/HLRfNxYAHX9kedikiInGl4B/H7JJcrltcw2NvvE9n38GwyxERiRsF/zHc8aH59A4O84MV74ddiohI3Cj4j+GM2mIuPbmcB1/dTt+grscrIslBwT+Bu35vIW3dAzz8+o6wSxERiQsF/wQumFfG5Qsrue/X79LVr7F+ETnxKfhj8D+vWsT+Awf53svbwi5FRGTKFPwxOLOumOsW17Ds5W3s7DgQdjkiIlOi4I/RvdeeSpoZ//jTTWGXIiIyJQr+GNWW5PKZD5/Mz97azStb2sMuR0TkuCn4J+GOD81jbnke/+vp9ZreKSInLAX/JGRnpPPPf3QmO/Ye4Csvbg67HBGR46Lgn6RLTqrglovm8sCr21m5o2PiJ4iIJBgF/3G455pTqC3J5XOPr9OQj4iccBT8xyE/O4N/uWExO/b28nfPvBV2OSIik6LgP06XnFTBp684iR+u3MlPdH1eETmBxHKx9QfNrNXMNoyz/Aoz6zSzNcHtC1HLrjazzWa21czuiWfhieCvPrKQxrmlfP7J9Wxv7534CSIiCSCWPf6HgKsn6PMbdz87uH0RwMzSgW8B1wCnATeZ2WlTKTbRZKSn8Y2bziEzI40///dVHBgcCrskEZEJTRj87v4ycDzTVy4Atrr7NncfBB4Drj+O35PQZpfk8rU/PZvNe7r53I/X4e5hlyQickzxGuO/2MzWmtnzZnZ60FYLRF+tvCloSzpXLKrinqtP4afrW/jmL7eGXY6IyDFlxOF3rAbmunuPmV0LPA0smOwvMbOlwFKA+vr6OJQ1s5ZeNp+3d3fzleXvsLC6kI+eXh12SSIiY5ryHr+7d7l7T3D/OSDTzCqAZmBOVNe6oG2837PM3RvdvbGysnKqZc04M+Of/+hMzppTwl2P/Y5V7+0LuyQRkTFNOfjNrNrMLLh/QfA79wJvAgvMbJ6ZZQE3As9M9fUSWU5mOg/c1kh1UQ63P/wmW1t7wi5JROQosUznfBR4HVhkZk1mdruZ3WlmdwZdbgA2mNla4BvAjR4xBHwGeAHYBPzI3ZP+bKeKgmwe/tQFZKQZtz34Bnu6+sMuSUTkMJaIs1AaGxt95cqVYZcxJeubOrlx2evUluby6H+9iPKC7LBLEpEkZmar3L0xlr46c3eanFlXzPdua+T9jgPcfP8KOnoHwy5JRARQ8E+rS06q4P5bz2d7ey9/dv8K9h9Q+ItI+BT802zJggq+d2sjW9t6uPn+FbT3DIRdkoikOAX/DLhsYSXLbjmPd9t6+JP7Xqdpny7YLiLhUfDPkCsWVfHvt19Ie88AN3zndbbs6Q67JBFJUQr+GdTYUMYP/9vFDLvzx999XVfwEpFQKPhn2Kk1RTxx5yWU5mXxX763gidWNYVdkoikGAV/COrL83jq05fQ2FDK3T9eyz8/v4nhQ4l3PoWIJCcFf0hK8rJ4+FMXcPOF9Xz319tY+v2VdB44GHZZIpICFPwhykxP4x/+8Ay+eP3pvLyljWu/8RvW7NwfdlkikuQU/CEzM269uIEf33kJAH9832s8+Mp2XdBFRKaNgj9BnD2nhJ/+9yVcvrCSLz67kTseXkmrvuBNRKaBgj+BlORl8b1bG/nCdafxytZ2rvray/zH2l1hlyUiSUbBn2DMjE8tmcdzd32IhvJ8/vLR3/EXj6zWVz2ISNwo+BPUSZUFPH7nxfz11Yt4ceNuPvyvv+Lffvuepn2KyJQp+BNYRnoan77iZJ6/6zLOqC3mfz+9gY9/+1XWauaPiEyBgv8EcHJVAY/ccSFfv/FsWjr7+cNvv8rnfryWls6+sEsTkROQgv8EYWZcf3Ytv7j7cu5YMo+frNnFFV/+FV/62dt09unELxGJnS69eILa2XGAr7y4mafX7KIkL5NPX3ESN184l/zsjLBLE5EQxPXSi2b2oJm1mtmGcZbfbGbrzGy9mb1mZmdFLdsRtK8xMyV5HM0py+NrN57Ds3+5hDNri/mn595myZd+ybde2kpXvz4BiMj4JtzjN7PLgB7g++5+xhjLLwE2ufs+M7sG+Dt3vzBYtgNodPf2yRSlPf7JW/XePr75yy28tLmNopwMPnFJA7dc3EBloS7yLpIKJrPHH9NQj5k1AM+OFfxH9CsFNrh7bfB4Bwr+GbWhuZP/+8stvPDWHrLS0/jYWbP55KUNnFFbHHZpIjKNJhP88R4Qvh14PuqxAy+amQPfdfdlcX49OcIZtcV895ZG3m3r4eHXdvD4qiaeWN3EBQ1l3HZJAx85rYrsjPSwyxSREMVtj9/MrgS+DSxx971BW627N5tZFbAc+Et3f3mc5y8FlgLU19ef9957703yT5GxdPYd5Edv7uSh13bQvL+Psvws/vDsWv70/Dksqi4MuzwRiZMZH+oxs8XAU8A17v7OOH3+Duhx93+d6PU01BN/w4ecl7e08aM3d/LzTXs4OOycNaeEP2ms45ozaijLzwq7RBGZghkNfjOrB34J3Orur0W15wNp7t4d3F8OfNHdfzbR6yn4p9fengGe+l0zP1q5k3f29JCeZiw5uYKPnTWbq06fRVFOZtglisgkxTX4zexR4AqgAtgD/C2QCeDu95nZ/cB/BkbGZobcvdHM5hP5FACRYwk/cPd/jKUoBf/McHc2tnTx7LoW/mPtLpr29ZGVnsZlCyv56Omz+PApVZQXaFaQyIkg7nv8M03BP/PcnbVNnfzH2l08t76Fls5+zODc+lI+cuosPnJqFSdXFWBmYZcqImNQ8MuUuDtv7eri55v28PNNe9jQ3AXA3PI8PrSggiUnV3Dx/AqK8zQkJJIoFPwSVy2dffxiUysvvd3Kb7ftpXdwmDSDM+tKWHJyOZeeXMG59aXkZGqaqEhYFPwybQ4OH2Ltzv28srWdV7e287v39zN0yMlKT2NxXTHnNZRy/twyzptbSqlmConMGAW/zJiegSFWbNvLG9s7eHNHB+ubOzk4HPk/dXJVAY1zSzl3bimL64o5ubKAjHR9IazIdFDwS2j6Dw6zrqmTN3d0sOq9fazc0UFX/xAAOZlpnD67mDNri1lcF7nNqyggPU0HjEWmSsEvCePQIWf73l7WN3WyrqmT9c372dDcRd/BYQDys9I5paaIRdWFnFJdyKJZhZxSXaQDxyKTpOCXhDZ8yHm3rSeyIWjaz6aWbt7e3TX6yQCgpjiHRdWFoxuEkyoLmF9ZQIGuNyAypjC/pE1kQulpxsJZhSycVcgN59UBkSmku7v6eXt3N5uD26aWLl7d2j56zACgqjCb+ZX5zK8sYH5FfrBByKeuNE9DRiIxUvBLQjAzaopzqSnO5cpFVaPtB4cPsaO9l3fbeni3rZdtbb1sa+/hp+taDrvkZFZ6GnPL86gvy2NOcKsvG3mcS16W/quLjNC7QRJaZnoaC2YVsmDW4d8k6u509A6yrb2XbcFGYXt7Lzs7DoyeaxCtoiBrdGMwpzSyMagpzmV2SQ41xbm6ZKWkFP1vlxOSmVFekE15QTbnN5Qdtmxko7BzXx/vdxxgZ3B7v+MAq9/fx7PrWhg+dPixraKcDGaX5FJTnENNSS6ziyMbhJqSHGYX51JdnKMT1CRpKPgl6URvFM6eU3LU8oPDh9jd2U9LZz8tnX3s2j/yM3J/zc797Dtw9HWLy/KzqCrMprIwm6rCHKqKsplVmE1VUQ5VUW3aQEiiU/BLyslMTxs9DjCevsFhWjr7aOnsZ9f+yM/dXf20dg3Q1t3P1tYe2roHGDp09Ky4wpyMwzYEI/crCrOoKMimPD+bioIsyvKzdEKbhELBLzKG3Kz0yMyhyoJx+xw65HQcGKS1a4DW7n5auwdo6x6gtStyf09XP6ve20dr9wCDQ4fG/B2leZmRTyf5WVQUZlORn0V5QXZkA1GQRUVBsLEoyCY/K13fjipxoeAXOU5paUZFENKnUTRuP3enq2+I9t4B9vYMsrdngPbeQdq7B9g72jbIpl1dtPcMHHY+Q7TsjLTg9bIO21iU52dFbSgiP8vy9GlCxqfgF5lmZkZxXibFeZmcVDlx/8GhQ3T0DtLeM0B7T7Bh6B2gvWdw9HFrdz8bd3Wxt3fgsPMcPnhNKM3Lojw/a3SDUHHExqK8IJvKYEORp08TKUXBL5JgsjLSqC7Oobo4Z8K+7k5X/9AHG4hgY9E+srHojvzcuKuLtp4Busf5NJGTmTY6pFQRtbEoDz5hjHySKM/Ppiw/SyfLneAU/CInMDOjODeT4tzYPk0MDA1HPk10D44OPUU2GpH7bT0DtHT2s2FXJ3t7Bsc8eG0GZXmHbxwiw00ffLKIHNTOoaJAQ06JSMEvkkKyM9JHz5CeyKFDTlf/wQ8+QURtJD44RjHI+qb9tPcM0jNw9KcJMyjPzzpqhtPo/WAqbGVhNtkZmgY7U2IKfjN7ELgOaHX3M8ZYbsDXgWuBA8An3H11sOw24H8FXf/B3R+OR+EiMr3S0oySvCxK8rI4uWri/v0Hh9nbO3jYzKbWw+5Hjku09wwwxgcJSvIyqSrMZlZRzgfnShRGPj3MKsqhpjiHWUU5ZOoTxJTFusf/EPBN4PvjLL8GWBDcLgS+A1xoZmXA3wKNgAOrzOwZd983laJFJPHkZKZTW5JLbcmxP00MH3L29g58MA22a2B0wzBy/93WHtp6jj5wbQaVBdmRM6yDM6pnl+RQXRw527paG4eYxBT87v6ymTUco8v1wPc98h3PvzWzEjOrAa4Alrt7B4CZLQeuBh6dStEicuJKT7Ngbz4HKB6336FDzv6+g7R297O7s/+ws61bOvvZ2tbDb7a0HfW9TGaRb3GN3hjUluRSV5pLXWnku5pS/XoP8RrjrwV2Rj1uCtrGaz+KmS0FlgLU19fHqSwROVGlpRll+ZEznE+pHv88ia7+g+wOzrDe3dnPrs5+dgcbhy2tPbz8ztEbh8KcjNEv65tTmkddae7o2dx1pcn/ba4J89e5+zJgGUQuxBJyOSJygijKyaQoJ5OFR3yD64iRE+h27jtA074D7OzoY+e+yBf3bWvr5dfvtNF/8PAzq0e+zXVeeT7zKvKZVxn8rMhPio1CvP6CZmBO1OO6oK2ZyHBPdPuv4vSaIiIT+uAEumLOqD16aMndae8ZHN0YNO3ro2nfAd7bG/mK7yd/13xY/+qiHOZV5NNQkc/8YGMwvzKfueX5J8z5DfEK/meAz5jZY0QO7na6e4uZvQD8k5mVBv2uAu6N02uKiEyZmVEZTCk9t770qOV9g8Ps2Bu53sP29sjFgLa39/DCW7vp6B0c7ZeVkcaCqgIWzSpkYXD96IXVhcwuzkm4s6Jjnc75KJE99wozayIyUycTwN3vA54jMpVzK5HpnJ8MlnWY2d8Dbwa/6osjB3pFRE4EuVnpnFpTxKk1Rx9n2H9gkO3tvWxt7WFLaw+bd3fz+hGfEgqyM1g4q4BF1YWcPruYxXXFLKouDPW8BV1sXUQkzjr7DrJlTzdv7+7mnT2Ra0i/vbt79HKhmemR604vrosMP51ZO/WNwWQutq7gFxGZAe5O074+1jd3sq6pkw3Nnaxv7hzdGGSlp3H2nBIeW3oRacdxrGAywX/iH54WETkBmNnolNFrz6wBIhuDnR0jG4P9dPYdPK7QnywFv4hISMyM+vI86svz+E+La2bsdXVes4hIilHwi4ikGAW/iEiKUfCLiKQYBb+ISIpR8IuIpBgFv4hIilHwi4ikmIT8ygYzawPeO86nVwDtcSwn3hK9PlCN8ZDo9UHi15jo9UFi1TjX3Stj6ZiQwT8VZrYy1u+rCEOi1weqMR4SvT5I/BoTvT44MWoci4Z6RERSjIJfRCTFJGPwLwu7gAkken2gGuMh0euDxK8x0euDE6PGoyTdGL+IiBxbMu7xi4jIMSRN8JvZ1Wa22cy2mtk9IdYxx8xeMrONZvaWmd0VtJeZ2XIz2xL8LA3azcy+EdS9zszOnaE6083sd2b2bPB4npmtCOr4oZllBe3ZweOtwfKGGaqvxMweN7O3zWyTmV2cSOvQzP4q+PfdYGaPmllO2OvQzB40s1Yz2xDVNul1Zma3Bf23mNltM1Djl4N/53Vm9pTCsb5rAAAEP0lEQVSZlUQtuzeocbOZfTSqfdre72PVGLXsbjNzM6sIHoeyHqfM3U/4G5AOvAvMB7KAtcBpIdVSA5wb3C8E3gFOA/4FuCdovwf4UnD/WuB5wICLgBUzVOf/AH4APBs8/hFwY3D/PuDPg/ufBu4L7t8I/HCG6nsYuCO4nwWUJMo6BGqB7UBu1Lr7RNjrELgMOBfYENU2qXUGlAHbgp+lwf3Saa7xKiAjuP+lqBpPC97L2cC84D2ePt3v97FqDNrnAC8QOceoIsz1OOW/MewC4vQPdTHwQtTje4F7w64rqOUnwO8Dm4GaoK0G2Bzc/y5wU1T/0X7TWFMd8Avgw8CzwX/a9qg33+j6DP6jXxzczwj62TTXVxwEqx3RnhDrkEjw7wze1BnBOvxoIqxDoOGIUJ3UOgNuAr4b1X5Yv+mo8YhlHwceCe4f9j4eWY8z8X4fq0bgceAsYAcfBH9o63Eqt2QZ6hl5I45oCtpCFXykPwdYAcxy95Zg0W5gVnA/jNq/Bvw1cCh4XA7sd/ehMWoYrS9Y3hn0n07zgDbg/wXDUfebWT4Jsg7dvRn4V+B9oIXIOllFYq3DEZNdZ2G/lz5FZA+aY9Qy4zWa2fVAs7uvPWJRwtQ4GckS/AnHzAqAJ4DPuntX9DKP7AKEMp3KzK4DWt19VRivH6MMIh+1v+Pu5wC9RIYpRoW8DkuB64lsoGYD+cDVYdQyGWGus1iY2d8AQ8AjYdcSzczygM8DXwi7lnhJluBvJjL+NqIuaAuFmWUSCf1H3P3JoHmPmdUEy2uA1qB9pmu/FPgDM9sBPEZkuOfrQImZZYxRw2h9wfJiYO801geRvaMmd18RPH6cyIYgUdbhR4Dt7t7m7geBJ4ms10RahyMmu85CeS+Z2SeA64Cbgw1UItV4EpGN/NrgfVMHrDaz6gSqcVKSJfjfBBYEsyqyiBxAeyaMQszMgAeATe7+1ahFzwAjR/ZvIzL2P9J+azA74CKgM+qjedy5+73uXufuDUTW0y/d/WbgJeCGceobqfuGoP+07jW6+25gp5ktCpp+D9hIgqxDIkM8F5lZXvDvPVJfwqzDKJNdZy8AV5lZafDJ5qqgbdqY2dVEhh7/wN0PHFH7jcGsqHnAAuANZvj97u7r3b3K3RuC900TkQkcu0mg9TgpYR9kiNeNyNH1d4gc7f+bEOtYQuTj9DpgTXC7lsiY7i+ALcDPgbKgvwHfCupeDzTOYK1X8MGsnvlE3lRbgR8D2UF7TvB4a7B8/gzVdjawMliPTxOZGZEw6xD4P8DbwAbg34jMPAl1HQKPEjnmcJBION1+POuMyDj71uD2yRmocSuR8fCR98t9Uf3/JqhxM3BNVPu0vd/HqvGI5Tv44OBuKOtxqjeduSsikmKSZahHRERipOAXEUkxCn4RkRSj4BcRSTEKfhGRFKPgFxFJMQp+EZEUo+AXEUkx/x/yRBHKsiigaAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "cost_function = red_iris.loss_curve_\n",
    "plt.figure()\n",
    "plt.plot(cost_function)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
